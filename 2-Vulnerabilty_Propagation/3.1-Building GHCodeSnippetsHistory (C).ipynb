{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pickle import Pickler\n",
    "import git\n",
    "import subprocess\n",
    "from os import getcwd\n",
    "from os import chdir\n",
    "from subprocess import Popen\n",
    "from subprocess import PIPE, STDOUT\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_c = os.listdir('dicts_c')\n",
    "len(dicts_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 54 #CHANGE IT FOR EVERY FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = dicts_c[i].split('.')[0]\n",
    "repo_name = file_name.replace('_','/')\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('dicts_c/'+dicts_c[i], 'rb') as f:\n",
    "        file_content = pickle.load(f)\n",
    "except MemoryError:\n",
    "    print(\"File cannot be opened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content_df = pd.DataFrame.from_dict(file_content, orient='index')\n",
    "hash_releases = file_content_df['release']\n",
    "len(hash_releases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = repo_name.split('/')[-1]\n",
    "repo = git.Repo.clone_from('https://github.com/'+repo_name+'.git', folder)#no_checkout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_and_dates = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = getcwd()\n",
    "\n",
    "git.Repo(ROOT_PATH+'/'+folder)\n",
    "\n",
    "# Change to directory\n",
    "chdir(ROOT_PATH+'/'+folder)\n",
    "\n",
    "for release in hash_releases:\n",
    "    with Popen(\n",
    "        args=['git', 'show', '-s', '--format=%ci' , release],\n",
    "        shell=False,\n",
    "        stdout=PIPE,\n",
    "        bufsize=1,\n",
    "        universal_newlines=True,\n",
    "    ) as process:\n",
    "\n",
    "        for line in process.stdout:\n",
    "            hash_and_dates[release] = line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_release = sorted(hash_and_dates.values())[0]\n",
    "oldest_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_for_checkout = list(hash_and_dates.keys())[list(hash_and_dates.values()).index(oldest_release)]\n",
    "commit_for_checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git.checkout(commit_for_checkout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execute nicad for each file for release \"+commit_for_checkout)\n",
    "\n",
    "p = Popen(['C:/cygwin64/bin/bash.exe', '-c', '. /etc/profile; '+\n",
    "'nicad6cross functions c C:/Users/Grazia/Desktop/Tesi/StackOverflow_Vulnerabilities/2-Vulnerabilty_Propagation/to_check '+ \n",
    "           'C:/Users/Grazia/Desktop/Tesi/StackOverflow_Vulnerabilities/2-Vulnerabilty_Propagation/'+folder], \n",
    "  stdout=PIPE, stderr=STDOUT)\n",
    "p.communicate()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "files_to_check_with_cppcheck = dict()\n",
    "\n",
    "if os.path.exists('to_check_functions-blind-crossclones/to_check_functions-blind-crossclones-0.30.xml'):\n",
    "    tree = ET.parse('to_check_functions-blind-crossclones/to_check_functions-blind-crossclones-0.30.xml')\n",
    "    root = tree.getroot()\n",
    "    for clones in root.findall('clone'):\n",
    "        for source in clones:\n",
    "            if folder in source.attrib['file']:\n",
    "                try:\n",
    "                    files_to_check_with_cppcheck[idx] = {\n",
    "                        'file': source.attrib['file'],\n",
    "                        'start': source.attrib['startline'],\n",
    "                        'end': source.attrib['endline']\n",
    "                    }\n",
    "                    idx = idx + 1\n",
    "                except KeyError as e:\n",
    "                    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_to_check_with_cppcheck.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH+'/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_snippets_with_vuln = dict()\n",
    "idx = 0\n",
    "\n",
    "key_n = 0\n",
    "for key in files_to_check_with_cppcheck.keys():\n",
    "    try:\n",
    "        print(\"Key \"+str(key_n))\n",
    "        code_context = []\n",
    "        path = files_to_check_with_cppcheck[key]['file']\n",
    "        print(path)\n",
    "        proc = subprocess.run([\"cppcheck\", \"--enable=style\", \"--template={cwe};{file};{line};{severity};{code}\", path], capture_output=True)\n",
    "\n",
    "        print(proc.stdout)\n",
    "        result = proc.stderr.decode('utf-8')\n",
    "\n",
    "        if result:\n",
    "            items = result.split('\\r\\n')\n",
    "            items = list(filter(None, items))\n",
    "\n",
    "            for x, y in zip(*[iter(items)] * 2):\n",
    "                row = x + y\n",
    "                row = row.split(';')\n",
    "                print(\"Flaw found at line \"+row[2])\n",
    "                print(\"Clone start a line \"+files_to_check_with_cppcheck[key]['start']+' and end at line '+files_to_check_with_cppcheck[key]['end'])\n",
    "                if int(row[2])>=int(files_to_check_with_cppcheck[key]['start']) and int(row[2])<=int(files_to_check_with_cppcheck[key]['end']):\n",
    "                    code_context = []\n",
    "                    with open(path, 'rb') as f:\n",
    "                        content = f.readlines()\n",
    "                        start = int(files_to_check_with_cppcheck[key]['start']) - 1\n",
    "                        end = int(files_to_check_with_cppcheck[key]['end']) - 1\n",
    "                        for number in range(start, end+1):\n",
    "                            code_context.append(content[number].decode('utf-8'))\n",
    "\n",
    "                    #chdir(ROOT_PATH+'/'+folder)\n",
    "                    with Popen(\n",
    "                    args=['git', 'log', '--reverse', '--pretty=format:%H', '-L', \n",
    "                          files_to_check_with_cppcheck[key]['start']+','+files_to_check_with_cppcheck[key]['end']+\":\"+path],\n",
    "                    shell=False,\n",
    "                    stdout=PIPE,\n",
    "                    bufsize=1,\n",
    "                    universal_newlines=True,\n",
    "                    ) as process:\n",
    "                        for line in process.stdout:\n",
    "                            #print(\"commit \"+line.strip())\n",
    "                            origin_commit = line.strip()\n",
    "                            break;\n",
    "\n",
    "                        with Popen(\n",
    "                            args=['git', 'show', '-s', '--format=%ci' , origin_commit],\n",
    "                            shell=False,\n",
    "                            stdout=PIPE,\n",
    "                            bufsize=1,\n",
    "                            universal_newlines=True,\n",
    "                        ) as process:\n",
    "\n",
    "                            for line in process.stdout:\n",
    "                                date = line.strip()\n",
    "\n",
    "                    clone_snippets_with_vuln[idx]={'repo': repo_name, 'origin_commit': origin_commit, 'file': path, #path.split(folder)[1][1:], \n",
    "                                                   'code_context': ''.join(code_context), 'commit_date': date, 'line_vuln': row[2], 'code_vuln': row[4]}\n",
    "                    idx = idx + 1\n",
    "                print()\n",
    "        key_n = key_n + 1\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = getcwd()\n",
    "prefix = prefix.replace('\\\\', '/')\n",
    "print(prefix)\n",
    "for key in clone_snippets_with_vuln.keys():\n",
    "    print(clone_snippets_with_vuln[key]['file'])\n",
    "    clone_snippets_with_vuln[key]['file'] = clone_snippets_with_vuln[key]['file'].replace('C:/Users/Grazia/Desktop/Tesi/StackOverflow_Vulnerabilities/2-Vulnerabilty_Propagation/'+folder+'/', '')\n",
    "    print(clone_snippets_with_vuln[key]['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clone_snippets_with_vuln:\n",
    "    clone_snippets_with_vuln_df = pd.DataFrame.from_dict(clone_snippets_with_vuln, orient='index')\n",
    "else:\n",
    "    print(\"Check next repository\")\n",
    "    shutil.rmtree('to_check_functions-blind-crossclones')\n",
    "    all_files = os.listdir()\n",
    "\n",
    "    for item in all_files:\n",
    "        if item.endswith(\".log\"):\n",
    "            os.remove(item)\n",
    "\n",
    "    for item in all_files:\n",
    "        if item.startswith(folder) and item.endswith('.xml'):\n",
    "            os.remove(item)\n",
    "    os.system('rmdir /S /Q \"{}\"'.format(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_snippets_with_vuln_df = clone_snippets_with_vuln_df.drop_duplicates().reset_index(drop=True)\n",
    "clone_snippets_with_vuln_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rmdir /S /Q \"{}\"'.format(folder))\n",
    "repo = git.Repo.clone_from('https://github.com/'+repo_name+'.git', folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH+'/'+folder)\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.run([\"git\",  \n",
    "                   \"log\",\n",
    "                   '-M',\n",
    "                   '--diff-filter=R',\n",
    "                   \"--summary\",\n",
    "                   \"--reverse\",\n",
    "                      '>',\n",
    "                      'file_renamed.txt'],\n",
    "                  shell=True) # if at the latest commit the path does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # if at the latest commit the path does not exist\n",
    "index_row = 0\n",
    "with open('file_renamed.txt', 'r') as f:\n",
    "    print(clone_snippets_with_vuln_df['file'][index_row].split('/')[-1])\n",
    "    lines = f.readlines()\n",
    "    replaced = False\n",
    "    for line in lines:      \n",
    "            if clone_snippets_with_vuln_df['file'][index_row].split('/')[-1] in line:\n",
    "                print(line)\n",
    "                sx_bracket = line.index('{')\n",
    "                dx_bracket = line.index('}')\n",
    "                index_arrow = line.index('=>')\n",
    "\n",
    "                print(\"Old\")\n",
    "                old = line[sx_bracket+1:index_arrow-1]\n",
    "                print(old.strip())\n",
    "                print(\"To substitute\")\n",
    "                substitute = line[index_arrow+3:dx_bracket]\n",
    "                print(substitute.strip())\n",
    "                old_path = clone_snippets_with_vuln_df['file'][index_row]\n",
    "                clone_snippets_with_vuln_df['file'][index_row] = clone_snippets_with_vuln_df['file'][index_row].replace(old.strip(), substitute.strip())\n",
    "                replaced=True\n",
    "                print(clone_snippets_with_vuln_df['file'][index_row].split('/')[-1])\n",
    "if replaced == False:\n",
    "    print(\"The file may be deleted\")\n",
    "else:\n",
    "    print(\"The file path is renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(clone_snippets_with_vuln_df.shape[0]):\n",
    "    print('Key_index '+str(index))\n",
    "    print(clone_snippets_with_vuln_df['file'][index])\n",
    "    repo.git.checkout('master')\n",
    "    proc = subprocess.run([\"git\", \n",
    "                           \"log\",\n",
    "                           '--pretty=format:%H',\n",
    "                           \"--follow\",\n",
    "                           \"--\",\n",
    "                           clone_snippets_with_vuln_df['file'][index]], \n",
    "                          capture_output=True) \n",
    "\n",
    "    commits = proc.stdout.decode('utf-8').split('\\n')\n",
    "    commits.reverse()\n",
    "\n",
    "        \n",
    "    start_from = commits.index(clone_snippets_with_vuln_df['origin_commit'][index])+1\n",
    "\n",
    "    print(\"Start from \"+str(start_from))\n",
    "    \n",
    "    if len(commits)==1:\n",
    "        print(\"This is the only commit on this file\")\n",
    "    else:\n",
    "        try:\n",
    "            for number in range(start_from, len(commits)):\n",
    "                repo.git.checkout(commits[number])\n",
    "                print('Checkout at commit '+commits[number])\n",
    "                to_delete = []\n",
    "                add_to_code_context = []\n",
    "                \n",
    "                print(commits[number])\n",
    "                print(\"Run diff for \"+clone_snippets_with_vuln_df['file'][index])\n",
    "                proc = subprocess.run([\"git\", \n",
    "                                       \"diff\",\n",
    "                                       commits[number-1]+\"..\"+commits[number],\n",
    "                                       '--',\n",
    "                                        clone_snippets_with_vuln_df['file'][index]\n",
    "                                      ],\n",
    "                                      capture_output=True)\n",
    "\n",
    "                if proc.stdout:\n",
    "                    deleted = []\n",
    "                    added = []\n",
    "                    print(\"Diff for \"+clone_snippets_with_vuln_df['file'][index])\n",
    "                    with open('diff.txt', 'w', encoding='utf-8') as f:\n",
    "                        f.write(proc.stdout.decode('utf-8'))\n",
    "                    with open('diff.txt', 'r') as f:\n",
    "                        context_index = None\n",
    "                        context_line = None\n",
    "                        print(\"Read diff\")\n",
    "                        content = f.readlines()\n",
    "\n",
    "                        for line in content:\n",
    "                            if line.startswith('-'):\n",
    "                                deleted.append(line[1:])\n",
    "                            if line.startswith('+'):\n",
    "                                added.append(line[1:])\n",
    "\n",
    "                        print(\"Analyze lines added\")\n",
    "                        print(added)\n",
    "                        for added_line in added:\n",
    "                            added_line_index = None\n",
    "                            \n",
    "                            if not added_line.startswith('++'):\n",
    "                                print(\"Check \"+added_line)\n",
    "                \n",
    "                                with open(clone_snippets_with_vuln_df['file'][index], 'r') as f:\n",
    "                                    lines_cc = f.readlines();\n",
    "\n",
    "\n",
    "                                    for x in lines_cc:\n",
    "                                        x = x.replace('\\n', '').replace('\\r', '')\n",
    "                                        if x != '' and x in clone_snippets_with_vuln_df['code_context'][index].split('\\r\\n')[0]:\n",
    "                                            context_line = x\n",
    "                                            print(x)\n",
    "                                            print(clone_snippets_with_vuln_df['code_context'][index])\n",
    "                                            print('###')\n",
    "                                            break;\n",
    "\n",
    "                                    print(context_index)\n",
    "                                    print(added_line)\n",
    "                                    if context_line:\n",
    "                                        context_index = lines_cc.index(context_line+'\\n')\n",
    "                                        added_line_index = lines_cc.index(added_line)\n",
    "\n",
    "                                        print(context_index)\n",
    "                                        print(added_line_index)\n",
    "                                        row_diff = context_index - added_line_index\n",
    "                                        row_diff = abs(row_diff)\n",
    "                                        print(row_diff)\n",
    "                                        if row_diff>=0 and row_diff<=3:\n",
    "                                            print(\"Add to code context\")\n",
    "                                            add_to_code_context.append(added_line)\n",
    "\n",
    "                        print(\"Analyze lines deleted\")\n",
    "                        for line_deleted in deleted:\n",
    "                            line_deleted = line_deleted.replace('\\n', '')\n",
    "                            if line_deleted:\n",
    "                                if line_deleted  in clone_snippets_with_vuln_df['code_context'][index]:\n",
    "                                    if line_deleted and line_deleted != '{' and line_deleted != '}':\n",
    "                                        print(\"Append row\")\n",
    "\n",
    "                                        to_delete.append(line_deleted)\n",
    "\n",
    "\n",
    "\n",
    "                to_change =  clone_snippets_with_vuln_df['code_context'][index]\n",
    "                print(\"Code context updated before\")\n",
    "                print(to_change)\n",
    "                if to_delete:\n",
    "                    for entry in to_delete:\n",
    "                        to_change = to_change.replace(entry, \"\")\n",
    "\n",
    "                    print(commits[number])\n",
    "                    print(to_delete)\n",
    "                     #se sono rmaste solo parentesi graffe allora vedi se il file  stato spostato\n",
    "\n",
    "                    #analyze_moves = False\n",
    "                    for line in to_change:\n",
    "                        if line == '\\r' or line == '\\n' or line == '{' or line=='}':\n",
    "                            to_change = to_change.replace(line, '')\n",
    "                if add_to_code_context:\n",
    "                    string_to_add = ' '.join(add_to_code_context)\n",
    "                    to_change = string_to_add + to_change\n",
    "\n",
    "                print(\"Code context updated after\")\n",
    "                print(to_change)\n",
    "\n",
    "                if to_change == '':\n",
    "                    print('Check moves for '+clone_snippets_with_vuln_df['file'][index][1:])\n",
    "                \n",
    "                with Popen(\n",
    "                    args=['git', 'show', '-s', '--format=%ci' ,  commits[number]],\n",
    "                    shell=False,\n",
    "                    stdout=PIPE,\n",
    "                    bufsize=1,\n",
    "                    universal_newlines=True,\n",
    "                ) as process:\n",
    "\n",
    "                    for line in process.stdout:\n",
    "                        date = line.strip()\n",
    "                ghCodeSnippetHistory = ghCodeSnippetHistory.append({'repo': repo_name, 'origin_commit': commits[number], \n",
    "                                                    'file': clone_snippets_with_vuln_df['file'][index], \n",
    "                                           'code_context': to_change, \n",
    "                                                    'commit_date': date}, ignore_index=True)\n",
    "                print()\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Encoding error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH)\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_check_move = ghCodeSnippetHistory.loc[ghCodeSnippetHistory['code_context']=='']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_check_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH+'/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip if rows_to_check_move is empty\n",
    "repo.git.checkout('master')\n",
    "proc = subprocess.run([\"git\", \n",
    "                   \"log\",\n",
    "                   '-M',\n",
    "                   '--diff-filter=R',\n",
    "                   \"--summary\",\n",
    "                   \"--reverse\",\n",
    "                      '>',\n",
    "                      'file_renamed.txt'],\n",
    "                  shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip if rows_to_check_move is empty\n",
    "files = list(pd.unique(rows_to_check_move['file']))\n",
    "print(len(files))\n",
    "for _, row in rows_to_check_move.iterrows():\n",
    "    lines_collected = []\n",
    "    start_from_this_commit = row['origin_commit']\n",
    "    start_read = False \n",
    "    replaced = False\n",
    "\n",
    "    with open('file_renamed.txt', 'r') as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        show = False\n",
    "        for line in lines:\n",
    "            if line.strip().startswith('commit '+start_from_this_commit):\n",
    "                show = True\n",
    "            \n",
    "            if line.strip().startswith('commit ') and not line.strip().startswith('commit '+start_from_this_commit):\n",
    "                show = False\n",
    "            if show:\n",
    "                if row['file'].split('/')[-1] in line and row['file'] in files:\n",
    "                    print(line)\n",
    "                    start = line.index('{')+1\n",
    "                    end = line.index('}')\n",
    "                    between_brackets = line[start:end]\n",
    "                    index_arrow = between_brackets.index('=>')\n",
    "                    print(between_brackets)\n",
    "                    print(\"Old\")\n",
    "                    old = between_brackets[0:index_arrow]\n",
    "                    print(old.strip())\n",
    "                    print(\"To substitute\")\n",
    "                    substitute = between_brackets[index_arrow+3:len(between_brackets)]\n",
    "                    print(substitute.strip())\n",
    "                    old_path = row['file']\n",
    "                    files.remove(old_path)\n",
    "                    row['file'] = row['file'].replace(old.strip(), substitute.strip())\n",
    "                    replaced = True\n",
    "                    print(row['file'])\n",
    "                    \n",
    "                    with Popen(\n",
    "                            args=['git', 'show', '-s', '--format=%ci' ,  start_from_this_commit],\n",
    "                            shell=False,\n",
    "                            stdout=PIPE,\n",
    "                            bufsize=1,\n",
    "                            universal_newlines=True,\n",
    "                        ) as process:\n",
    "\n",
    "                            for line in process.stdout:\n",
    "                                date = line.strip()\n",
    "                    index_row =  clone_snippets_with_vuln_df.loc[clone_snippets_with_vuln_df['file']==old_path].index[0]\n",
    "                    ghCodeSnippetHistory.loc[_] = {'repo': repo_name, 'origin_commit': start_from_this_commit, \n",
    "                                    'file': row['file'], \n",
    "                           'code_context': clone_snippets_with_vuln_df.iloc[index_row, 3]    , \n",
    "                                    'commit_date': date}\n",
    "                    \n",
    "\n",
    "    if replaced == False and row['file'] in files:\n",
    "        print(\"The file may be deleted\")\n",
    "        ghCodeSnippetHistory = ghCodeSnippetHistory.drop([_])\n",
    "    if replaced==True:\n",
    "        print(\"The file path is renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH)\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH+'/'+folder)\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ghCodeSnippetHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory = ghCodeSnippetHistory.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck = dict()\n",
    "idx = 0\n",
    "num = 0\n",
    "for _, row in ghCodeSnippetHistory.iterrows():\n",
    "    if _ == 1:\n",
    "        path = 'xbmc/cores/paplayer/NSFCodec/src/memguard.c'\n",
    "    else:\n",
    "        path = row['file']\n",
    "    print(_)\n",
    "    print(row['origin_commit'])\n",
    "    print(path)\n",
    "    repo.git.checkout(row['origin_commit'])\n",
    "    proc = subprocess.run([\"cppcheck\", \"--enable=style\", \"--template={cwe};{file};{line};{severity};{code}\", path], capture_output=True)\n",
    "    result = proc.stderr.decode('utf-8')\n",
    "    print(proc.stdout)\n",
    "\n",
    "    if proc.stdout.decode('utf-8') == 'cppcheck: error: could not find or open any of the paths given.\\r\\n':\n",
    "        continue;\n",
    "\n",
    "    if result:\n",
    "        items = result.split('\\r\\n')\n",
    "        items = list(filter(None, items))\n",
    "        for x, y in zip(*[iter(items)] * 2):\n",
    "            row = x + y\n",
    "            row = row.split(';')\n",
    "\n",
    "            if not row[2]=='0':\n",
    "                print(\"Flaw found at line \"+row[2])\n",
    "                ghCodeSnippetHistory_aftercppcheck[idx] = {\n",
    "                    'repo': ghCodeSnippetHistory['repo'][_],\n",
    "                    'origin_commit': ghCodeSnippetHistory['origin_commit'][_],\n",
    "                    'file': ghCodeSnippetHistory['file'][_],\n",
    "                    'code_context': ghCodeSnippetHistory['code_context'][_],\n",
    "                    'commit_date': ghCodeSnippetHistory['commit_date'][_],\n",
    "                    'line_vuln': row[2],\n",
    "                    'code_vuln': row[4]\n",
    "                }\n",
    "                idx = idx + 1\n",
    "            else:\n",
    "                print(\"Syntax error\")\n",
    "                break;\n",
    "    else:\n",
    "        ghCodeSnippetHistory_aftercppcheck[idx] = {\n",
    "            'repo': ghCodeSnippetHistory['repo'][_],\n",
    "            'origin_commit': ghCodeSnippetHistory['origin_commit'][_] ,\n",
    "            'file': ghCodeSnippetHistory['file'][_] ,\n",
    "            'code_context': ghCodeSnippetHistory['code_context'][_], \n",
    "            'commit_date': ghCodeSnippetHistory['commit_date'][_],\n",
    "            'line_vuln': '',\n",
    "            'code_vuln': ''\n",
    "        }\n",
    "        idx = idx + 1\n",
    "    num = num + 1\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck = pd.DataFrame.from_dict(ghCodeSnippetHistory_aftercppcheck, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck = ghCodeSnippetHistory_aftercppcheck.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ghCodeSnippetHistory_aftercppcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.unique(ghCodeSnippetHistory_aftercppcheck['file'])\n",
    "\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_snippets_with_vuln_df.loc[clone_snippets_with_vuln_df['file']==files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck.loc[ghCodeSnippetHistory_aftercppcheck['file']==files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_initial = pd.unique(clone_snippets_with_vuln_df['code_vuln'])\n",
    "indexes = []\n",
    "for code in code_initial:\n",
    "    code = code.replace('\\r', '').replace('\\n','').replace('^','') \n",
    "    \n",
    "\n",
    "    for _,row in ghCodeSnippetHistory_aftercppcheck.iterrows():\n",
    "        code_gh = ghCodeSnippetHistory_aftercppcheck['code_vuln'][_]\n",
    "        code_gh = code_gh.replace('\\r', '').replace('\\n','').replace('^','') \n",
    "        if code in code_gh:\n",
    "            indexes.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck.iloc[indexes].drop_duplicates()# where code_vuln is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghCodeSnippetHistory_aftercppcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(ROOT_PATH)\n",
    "ghCodeSnippetHistory_aftercppcheck.to_csv('GHCodeSnippetHistory/history_'+file_name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
