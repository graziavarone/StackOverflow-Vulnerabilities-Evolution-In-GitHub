{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grazia\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (5.1.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Model initialized, training 8,485,121 parameters\n",
      "Restoring top model from step: 10\n",
      "Restored from step: 11\n",
      "MB: 500, seqs: 1,534, tokens: 353,158, loss: 3.733, total_acc: 48.04%, total_precision: 4.11%, total_recall: 1.74%, f1: 2.08%,  accs: 47.07%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 2.621, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 2\n",
      "MB: 1000, seqs: 2,942, tokens: 695,440, loss: 2.808, total_acc: 47.09%, total_precision: 0.07%, total_recall: 0.07%, f1: 0.07%,  accs: 47.02%\n",
      "MB: 1500, seqs: 4,276, tokens: 1,035,566, loss: 3.250, total_acc: 47.75%, total_precision: 1.65%, total_recall: 0.25%, f1: 0.39%,  accs: 47.60%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.068, total_acc: [0.50883394], total_precision: [0.06007067], total_recall: [0.0054609706], f1: [0.010011779], accs: 50.53%, distances: 18.396\n",
      "Step: 3\n",
      "MB: 2000, seqs: 5,643, tokens: 1,371,210, loss: 3.080, total_acc: 51.28%, total_precision: 4.72%, total_recall: 1.11%, f1: 1.79%,  accs: 50.99%\n",
      "MB: 2500, seqs: 7,005, tokens: 1,713,977, loss: 3.402, total_acc: 49.27%, total_precision: 12.11%, total_recall: 3.09%, f1: 4.54%,  accs: 48.38%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.440, total_acc: [0.5265018], total_precision: [0.14134276], total_recall: [0.050513975], f1: [0.073498234], accs: 51.59%, distances: 18.336\n",
      "Step: 4\n",
      "MB: 3000, seqs: 8,345, tokens: 2,056,054, loss: 3.377, total_acc: 50.37%, total_precision: 18.58%, total_recall: 4.80%, f1: 7.34%,  accs: 48.58%\n",
      "MB: 3500, seqs: 9,667, tokens: 2,396,710, loss: 3.610, total_acc: 48.34%, total_precision: 10.92%, total_recall: 3.04%, f1: 4.57%,  accs: 47.43%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.096, total_acc: [0.51943463], total_precision: [0.09893993], total_recall: [0.027738517], f1: [0.04327263], accs: 51.59%, distances: 18.343\n",
      "Step: 5\n",
      "MB: 4000, seqs: 11,009, tokens: 2,739,059, loss: 3.363, total_acc: 49.33%, total_precision: 8.60%, total_recall: 4.34%, f1: 5.59%,  accs: 48.21%\n",
      "MB: 4500, seqs: 12,378, tokens: 3,079,396, loss: 3.227, total_acc: 49.89%, total_precision: 13.15%, total_recall: 4.47%, f1: 6.41%,  accs: 48.43%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.242, total_acc: [0.51943463], total_precision: [0.113074206], total_recall: [0.050143026], f1: [0.06700014], accs: 51.24%, distances: 18.378\n",
      "Step: 6\n",
      "MB: 5000, seqs: 13,758, tokens: 3,417,830, loss: 3.508, total_acc: 50.14%, total_precision: 13.57%, total_recall: 4.71%, f1: 6.56%,  accs: 48.77%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.080, total_acc: [0.51943463], total_precision: [0.14840989], total_recall: [0.045936394], f1: [0.06750799], accs: 51.24%, distances: 18.371\n",
      "Step: 7\n",
      "MB: 5500, seqs: 15,082, tokens: 3,760,926, loss: 3.325, total_acc: 49.77%, total_precision: 10.71%, total_recall: 4.43%, f1: 6.00%,  accs: 48.94%\n",
      "MB: 6000, seqs: 16,498, tokens: 4,106,223, loss: 3.216, total_acc: 51.62%, total_precision: 11.03%, total_recall: 4.24%, f1: 5.72%,  accs: 50.85%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.109, total_acc: [0.5159011], total_precision: [0.10341578], total_recall: [0.04487633], f1: [0.05996971], accs: 50.88%, distances: 18.375\n",
      "Step: 8\n",
      "MB: 6500, seqs: 17,907, tokens: 4,449,204, loss: 3.243, total_acc: 48.76%, total_precision: 16.68%, total_recall: 6.44%, f1: 8.75%,  accs: 46.84%\n",
      "MB: 7000, seqs: 19,186, tokens: 4,784,543, loss: 3.390, total_acc: 49.96%, total_precision: 12.43%, total_recall: 6.45%, f1: 7.98%,  accs: 48.71%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.270, total_acc: [0.5159011], total_precision: [0.10895171], total_recall: [0.07332996], f1: [0.07970162], accs: 50.18%, distances: 18.382\n",
      "Step: 9\n",
      "MB: 7500, seqs: 20,485, tokens: 5,122,848, loss: 3.523, total_acc: 50.35%, total_precision: 16.65%, total_recall: 7.27%, f1: 9.43%,  accs: 48.19%\n",
      "MB: 8000, seqs: 21,916, tokens: 5,465,161, loss: 3.095, total_acc: 51.99%, total_precision: 15.73%, total_recall: 6.91%, f1: 8.98%,  accs: 50.59%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.154, total_acc: [0.5159011], total_precision: [0.11778564], total_recall: [0.07208481], f1: [0.083123006], accs: 50.18%, distances: 18.382\n",
      "Step: 10\n",
      "MB: 8500, seqs: 23,255, tokens: 5,804,435, loss: 3.443, total_acc: 49.37%, total_precision: 15.93%, total_recall: 6.88%, f1: 9.06%,  accs: 48.39%\n",
      "MB: 9000, seqs: 24,599, tokens: 6,146,542, loss: 3.207, total_acc: 50.97%, total_precision: 16.23%, total_recall: 8.17%, f1: 10.11%,  accs: 48.88%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.041, total_acc: [0.5123675], total_precision: [0.09673145], total_recall: [0.06403332], f1: [0.06939256], accs: 50.18%, distances: 18.392\n",
      "Step: 11\n",
      "MB: 9500, seqs: 25,911, tokens: 6,486,397, loss: 3.387, total_acc: 49.92%, total_precision: 15.63%, total_recall: 7.15%, f1: 9.19%,  accs: 47.94%\n",
      "MB: 10000, seqs: 27,248, tokens: 6,827,818, loss: 3.321, total_acc: 49.59%, total_precision: 14.28%, total_recall: 6.17%, f1: 8.05%,  accs: 47.94%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.292, total_acc: [0.5123675], total_precision: [0.12638398], total_recall: [0.08220596], f1: [0.0729682], accs: 50.18%, distances: 18.392\n",
      "Step: 12\n",
      "MB: 10500, seqs: 28,624, tokens: 7,167,071, loss: 3.118, total_acc: 51.45%, total_precision: 15.72%, total_recall: 7.33%, f1: 8.95%,  accs: 49.56%\n",
      "MB: 11000, seqs: 29,956, tokens: 7,506,092, loss: 3.156, total_acc: 50.75%, total_precision: 21.40%, total_recall: 10.23%, f1: 13.01%,  accs: 48.05%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.051, total_acc: [0.5159011], total_precision: [0.12650178], total_recall: [0.111543], f1: [0.11514948], accs: 49.82%, distances: 18.389\n",
      "Step: 13\n",
      "MB: 11500, seqs: 31,349, tokens: 7,849,572, loss: 3.191, total_acc: 50.04%, total_precision: 14.04%, total_recall: 7.77%, f1: 9.35%,  accs: 48.24%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.214, total_acc: [0.5300353], total_precision: [0.14096415], total_recall: [0.14851086], f1: [0.14356385], accs: 50.18%, distances: 18.269\n",
      "Step: 14\n",
      "MB: 12000, seqs: 32,740, tokens: 8,192,549, loss: 3.155, total_acc: 50.97%, total_precision: 17.98%, total_recall: 9.17%, f1: 11.38%,  accs: 48.89%\n",
      "MB: 12500, seqs: 34,039, tokens: 8,529,928, loss: 3.096, total_acc: 52.96%, total_precision: 18.72%, total_recall: 10.14%, f1: 12.16%,  accs: 50.35%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.174, total_acc: [0.5229682], total_precision: [0.13890292], total_recall: [0.10280544], f1: [0.11620266], accs: 50.53%, distances: 18.290\n",
      "Step: 15\n",
      "MB: 13000, seqs: 35,370, tokens: 8,871,459, loss: 3.292, total_acc: 51.92%, total_precision: 21.82%, total_recall: 10.05%, f1: 13.02%,  accs: 49.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: 13500, seqs: 36,708, tokens: 9,211,442, loss: 3.016, total_acc: 53.74%, total_precision: 19.88%, total_recall: 9.37%, f1: 11.85%,  accs: 51.42%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.232, total_acc: [0.5300353], total_precision: [0.12084806], total_recall: [0.074204944], f1: [0.091283865], accs: 51.59%, distances: 18.258\n",
      "Step: 16\n",
      "MB: 14000, seqs: 38,086, tokens: 9,554,042, loss: 3.242, total_acc: 51.23%, total_precision: 17.52%, total_recall: 9.12%, f1: 11.13%,  accs: 49.06%\n",
      "MB: 14500, seqs: 39,414, tokens: 9,891,857, loss: 3.216, total_acc: 50.90%, total_precision: 17.81%, total_recall: 9.40%, f1: 11.45%,  accs: 48.64%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.074, total_acc: [0.5229682], total_precision: [0.15418138], total_recall: [0.10724382], f1: [0.11563185], accs: 51.59%, distances: 18.286\n",
      "Step: 17\n",
      "MB: 15000, seqs: 40,759, tokens: 10,233,594, loss: 2.974, total_acc: 52.49%, total_precision: 18.91%, total_recall: 8.71%, f1: 11.29%,  accs: 50.63%\n",
      "MB: 15500, seqs: 42,097, tokens: 10,568,337, loss: 3.159, total_acc: 50.75%, total_precision: 17.71%, total_recall: 10.07%, f1: 12.16%,  accs: 48.43%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.313, total_acc: [0.5229682], total_precision: [0.16456336], total_recall: [0.07693084], f1: [0.09389198], accs: 51.59%, distances: 18.336\n",
      "Step: 18\n",
      "MB: 16000, seqs: 43,459, tokens: 10,912,266, loss: 3.055, total_acc: 51.69%, total_precision: 20.40%, total_recall: 12.36%, f1: 14.46%,  accs: 48.38%\n",
      "MB: 16500, seqs: 44,809, tokens: 11,251,884, loss: 3.234, total_acc: 52.30%, total_precision: 21.60%, total_recall: 11.33%, f1: 13.79%,  accs: 49.70%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 2.969, total_acc: [0.51943463], total_precision: [0.14723204], total_recall: [0.11731449], f1: [0.11925795], accs: 50.53%, distances: 18.336\n",
      "Step: 19\n",
      "MB: 17000, seqs: 46,169, tokens: 11,592,116, loss: 3.048, total_acc: 50.66%, total_precision: 19.52%, total_recall: 10.69%, f1: 12.91%,  accs: 48.24%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.144, total_acc: [0.53710246], total_precision: [0.1565371], total_recall: [0.104397334], f1: [0.122210994], accs: 53.00%, distances: 18.180\n",
      "Step: 20\n",
      "MB: 17500, seqs: 47,532, tokens: 11,933,324, loss: 2.983, total_acc: 52.09%, total_precision: 20.03%, total_recall: 10.23%, f1: 12.49%,  accs: 49.67%\n",
      "MB: 18000, seqs: 48,855, tokens: 12,273,047, loss: 3.113, total_acc: 51.85%, total_precision: 21.78%, total_recall: 10.99%, f1: 13.38%,  accs: 48.90%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.166, total_acc: [0.5335689], total_precision: [0.15047114], total_recall: [0.11545936], f1: [0.12997365], accs: 52.65%, distances: 18.251\n",
      "Step: 21\n",
      "MB: 18500, seqs: 50,264, tokens: 12,617,504, loss: 2.812, total_acc: 54.58%, total_precision: 19.55%, total_recall: 11.47%, f1: 13.63%,  accs: 52.31%\n",
      "MB: 19000, seqs: 51,555, tokens: 12,953,569, loss: 3.001, total_acc: 53.68%, total_precision: 14.84%, total_recall: 7.77%, f1: 9.79%,  accs: 51.74%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.033, total_acc: [0.5335689], total_precision: [0.14132594], total_recall: [0.12342252], f1: [0.13048966], accs: 52.65%, distances: 18.194\n",
      "Step: 22\n",
      "MB: 19500, seqs: 52,942, tokens: 13,295,089, loss: 3.027, total_acc: 52.42%, total_precision: 26.10%, total_recall: 14.75%, f1: 17.30%,  accs: 49.39%\n",
      "MB: 20000, seqs: 54,266, tokens: 13,633,581, loss: 3.059, total_acc: 53.17%, total_precision: 24.44%, total_recall: 12.72%, f1: 15.99%,  accs: 49.70%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.387, total_acc: [0.5265018], total_precision: [0.13981155], total_recall: [0.14544842], f1: [0.12826855], accs: 51.94%, distances: 18.230\n",
      "Step: 23\n",
      "MB: 20500, seqs: 55,684, tokens: 13,980,019, loss: 2.969, total_acc: 51.06%, total_precision: 26.34%, total_recall: 16.42%, f1: 18.62%,  accs: 46.76%\n",
      "MB: 21000, seqs: 56,988, tokens: 14,319,779, loss: 2.888, total_acc: 52.45%, total_precision: 20.76%, total_recall: 13.16%, f1: 15.03%,  accs: 49.39%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.154, total_acc: [0.53710246], total_precision: [0.17420495], total_recall: [0.13480566], f1: [0.14673567], accs: 53.00%, distances: 18.138\n",
      "Step: 24\n",
      "MB: 21500, seqs: 58,317, tokens: 14,660,133, loss: 2.931, total_acc: 54.25%, total_precision: 17.54%, total_recall: 10.38%, f1: 12.05%,  accs: 51.84%\n",
      "MB: 22000, seqs: 59,677, tokens: 14,998,801, loss: 3.009, total_acc: 52.43%, total_precision: 19.14%, total_recall: 11.51%, f1: 13.53%,  accs: 50.51%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.223, total_acc: [0.5265018], total_precision: [0.15682623], total_recall: [0.123125255], f1: [0.12893243], accs: 51.59%, distances: 18.145\n",
      "Step: 25\n",
      "MB: 22500, seqs: 60,998, tokens: 15,339,723, loss: 2.989, total_acc: 52.38%, total_precision: 18.32%, total_recall: 10.93%, f1: 12.42%,  accs: 50.42%\n",
      "MB: 23000, seqs: 62,365, tokens: 15,678,020, loss: 2.890, total_acc: 51.65%, total_precision: 24.53%, total_recall: 13.24%, f1: 15.62%,  accs: 49.38%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.234, total_acc: [0.5335689], total_precision: [0.20388693], total_recall: [0.15538068], f1: [0.15610524], accs: 52.30%, distances: 18.081\n",
      "Step: 26\n",
      "MB: 23500, seqs: 63,690, tokens: 16,020,541, loss: 3.000, total_acc: 52.08%, total_precision: 19.72%, total_recall: 11.25%, f1: 13.37%,  accs: 49.89%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.105, total_acc: [0.5441696], total_precision: [0.20140833], total_recall: [0.18324079], f1: [0.16754034], accs: 53.00%, distances: 18.011\n",
      "Step: 27\n",
      "MB: 24000, seqs: 65,072, tokens: 16,359,534, loss: 2.823, total_acc: 51.95%, total_precision: 19.75%, total_recall: 11.28%, f1: 13.24%,  accs: 49.86%\n",
      "MB: 24500, seqs: 66,381, tokens: 16,702,204, loss: 2.869, total_acc: 52.25%, total_precision: 23.35%, total_recall: 13.18%, f1: 15.47%,  accs: 49.89%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.153, total_acc: [0.54063606], total_precision: [0.19459869], total_recall: [0.16042404], f1: [0.15933904], accs: 53.36%, distances: 18.025\n",
      "Step: 28\n",
      "MB: 25000, seqs: 67,782, tokens: 17,044,128, loss: 2.872, total_acc: 53.39%, total_precision: 20.77%, total_recall: 10.22%, f1: 12.85%,  accs: 51.11%\n",
      "MB: 25500, seqs: 69,149, tokens: 17,385,365, loss: 2.818, total_acc: 53.04%, total_precision: 26.42%, total_recall: 14.36%, f1: 17.58%,  accs: 49.52%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.220, total_acc: [0.5547703], total_precision: [0.2148517], total_recall: [0.2106007], f1: [0.18232374], accs: 53.71%, distances: 17.876\n",
      "Step: 29\n",
      "MB: 26000, seqs: 70,506, tokens: 17,728,755, loss: 3.014, total_acc: 51.07%, total_precision: 22.01%, total_recall: 14.63%, f1: 16.54%,  accs: 47.53%\n",
      "MB: 26500, seqs: 71,879, tokens: 18,067,102, loss: 2.795, total_acc: 52.80%, total_precision: 19.53%, total_recall: 13.48%, f1: 14.93%,  accs: 50.40%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.013, total_acc: [0.55123675], total_precision: [0.25041226], total_recall: [0.16537103], f1: [0.17509894], accs: 54.42%, distances: 17.901\n",
      "Step: 30\n",
      "MB: 27000, seqs: 73,211, tokens: 18,407,309, loss: 2.812, total_acc: 54.65%, total_precision: 25.42%, total_recall: 14.59%, f1: 17.39%,  accs: 51.43%\n",
      "MB: 27500, seqs: 74,580, tokens: 18,747,006, loss: 2.778, total_acc: 54.42%, total_precision: 26.23%, total_recall: 15.56%, f1: 18.28%,  accs: 50.99%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.503, total_acc: [0.54063606], total_precision: [0.2235964], total_recall: [0.169157], f1: [0.17068446], accs: 53.36%, distances: 18.014\n",
      "Step: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: 28000, seqs: 75,881, tokens: 19,089,044, loss: 2.857, total_acc: 55.11%, total_precision: 24.02%, total_recall: 13.57%, f1: 16.13%,  accs: 51.58%\n",
      "MB: 28500, seqs: 77,248, tokens: 19,431,191, loss: 2.813, total_acc: 53.47%, total_precision: 22.99%, total_recall: 14.07%, f1: 16.30%,  accs: 50.91%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.010, total_acc: [0.5547703], total_precision: [0.24157834], total_recall: [0.20724382], f1: [0.1851995], accs: 53.71%, distances: 17.774\n",
      "Step: 32\n",
      "MB: 29000, seqs: 78,591, tokens: 19,772,049, loss: 2.777, total_acc: 53.83%, total_precision: 25.64%, total_recall: 15.21%, f1: 17.70%,  accs: 51.23%\n",
      "MB: 29500, seqs: 79,986, tokens: 20,111,503, loss: 2.725, total_acc: 52.90%, total_precision: 26.06%, total_recall: 15.25%, f1: 17.54%,  accs: 49.32%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.046, total_acc: [0.5547703], total_precision: [0.23075277], total_recall: [0.19495204], f1: [0.18247065], accs: 54.06%, distances: 17.781\n",
      "Step: 33\n",
      "MB: 30000, seqs: 81,354, tokens: 20,453,245, loss: 2.519, total_acc: 55.56%, total_precision: 28.92%, total_recall: 16.69%, f1: 19.63%,  accs: 51.75%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.259, total_acc: [0.5547703], total_precision: [0.22865975], total_recall: [0.18422934], f1: [0.18225062], accs: 53.71%, distances: 17.777\n",
      "Step: 34\n",
      "MB: 30500, seqs: 82,636, tokens: 20,792,958, loss: 2.810, total_acc: 53.82%, total_precision: 24.34%, total_recall: 15.25%, f1: 17.48%,  accs: 50.47%\n",
      "MB: 31000, seqs: 84,027, tokens: 21,133,902, loss: 2.761, total_acc: 54.92%, total_precision: 29.73%, total_recall: 19.15%, f1: 21.95%,  accs: 50.61%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.157, total_acc: [0.5441696], total_precision: [0.21790342], total_recall: [0.18297999], f1: [0.17088552], accs: 53.36%, distances: 17.933\n",
      "Step: 35\n",
      "MB: 31500, seqs: 85,372, tokens: 21,475,006, loss: 2.671, total_acc: 53.75%, total_precision: 24.28%, total_recall: 16.32%, f1: 18.06%,  accs: 50.48%\n",
      "MB: 32000, seqs: 86,736, tokens: 21,817,835, loss: 2.800, total_acc: 53.52%, total_precision: 23.40%, total_recall: 13.26%, f1: 15.40%,  accs: 51.47%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.054, total_acc: [0.5477032], total_precision: [0.2350996], total_recall: [0.19788828], f1: [0.17919095], accs: 53.00%, distances: 17.823\n",
      "Step: 36\n",
      "MB: 32500, seqs: 88,068, tokens: 22,156,104, loss: 2.725, total_acc: 54.35%, total_precision: 27.10%, total_recall: 18.81%, f1: 20.87%,  accs: 49.85%\n",
      "MB: 33000, seqs: 89,458, tokens: 22,499,988, loss: 2.602, total_acc: 54.96%, total_precision: 31.25%, total_recall: 18.37%, f1: 21.71%,  accs: 50.43%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.193, total_acc: [0.5477032], total_precision: [0.20679231], total_recall: [0.16863957], f1: [0.17306173], accs: 53.71%, distances: 17.926\n",
      "Step: 37\n",
      "MB: 33500, seqs: 90,750, tokens: 22,833,825, loss: 2.543, total_acc: 54.72%, total_precision: 25.23%, total_recall: 14.25%, f1: 17.08%,  accs: 51.78%\n",
      "MB: 34000, seqs: 92,100, tokens: 23,175,300, loss: 2.600, total_acc: 54.15%, total_precision: 26.91%, total_recall: 17.38%, f1: 19.50%,  accs: 50.89%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 2.865, total_acc: [0.5689046], total_precision: [0.25495833], total_recall: [0.22950529], f1: [0.21514781], accs: 53.71%, distances: 17.580\n",
      "Step: 38\n",
      "MB: 34500, seqs: 93,469, tokens: 23,518,561, loss: 2.564, total_acc: 53.69%, total_precision: 33.07%, total_recall: 20.19%, f1: 23.50%,  accs: 48.36%\n",
      "MB: 35000, seqs: 94,830, tokens: 23,861,102, loss: 2.716, total_acc: 54.81%, total_precision: 26.11%, total_recall: 16.02%, f1: 18.38%,  accs: 51.29%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.274, total_acc: [0.5547703], total_precision: [0.22647232], total_recall: [0.14200741], f1: [0.15954904], accs: 54.42%, distances: 17.866\n",
      "Step: 39\n",
      "MB: 35500, seqs: 96,205, tokens: 24,204,811, loss: 2.529, total_acc: 54.91%, total_precision: 26.37%, total_recall: 16.89%, f1: 19.14%,  accs: 51.35%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.273, total_acc: [0.55123675], total_precision: [0.23189747], total_recall: [0.18136042], f1: [0.18145128], accs: 53.36%, distances: 17.813\n",
      "Step: 40\n",
      "MB: 36000, seqs: 97,538, tokens: 24,545,292, loss: 2.778, total_acc: 54.76%, total_precision: 28.62%, total_recall: 16.57%, f1: 19.76%,  accs: 51.31%\n",
      "MB: 36500, seqs: 98,894, tokens: 24,884,133, loss: 2.530, total_acc: 52.80%, total_precision: 27.44%, total_recall: 18.18%, f1: 20.13%,  accs: 48.89%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.181, total_acc: [0.5583039], total_precision: [0.25], total_recall: [0.19951202], f1: [0.1921293], accs: 54.06%, distances: 17.703\n",
      "Step: 41\n",
      "MB: 37000, seqs: 100,270, tokens: 25,226,845, loss: 2.435, total_acc: 57.63%, total_precision: 33.59%, total_recall: 22.75%, f1: 25.24%,  accs: 53.34%\n",
      "MB: 37500, seqs: 101,573, tokens: 25,565,697, loss: 2.596, total_acc: 54.57%, total_precision: 29.05%, total_recall: 18.89%, f1: 21.46%,  accs: 50.81%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.171, total_acc: [0.5441696], total_precision: [0.20931041], total_recall: [0.15194348], f1: [0.15932469], accs: 53.36%, distances: 17.986\n",
      "Step: 42\n",
      "MB: 38000, seqs: 102,973, tokens: 25,909,257, loss: 2.494, total_acc: 56.00%, total_precision: 30.88%, total_recall: 20.05%, f1: 22.83%,  accs: 52.21%\n",
      "MB: 38500, seqs: 104,303, tokens: 26,249,487, loss: 2.456, total_acc: 55.64%, total_precision: 32.70%, total_recall: 21.25%, f1: 23.60%,  accs: 51.88%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.256, total_acc: [0.5583039], total_precision: [0.28331652], total_recall: [0.18346794], f1: [0.19947836], accs: 54.42%, distances: 17.689\n",
      "Step: 43\n",
      "MB: 39000, seqs: 105,699, tokens: 26,592,742, loss: 2.458, total_acc: 56.88%, total_precision: 33.09%, total_recall: 21.17%, f1: 24.14%,  accs: 52.58%\n",
      "MB: 39500, seqs: 107,023, tokens: 26,930,186, loss: 2.522, total_acc: 56.87%, total_precision: 30.82%, total_recall: 19.20%, f1: 22.20%,  accs: 53.93%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.274, total_acc: [0.56183743], total_precision: [0.2373411], total_recall: [0.1533653], f1: [0.17020023], accs: 54.77%, distances: 17.664\n",
      "Step: 44\n",
      "MB: 40000, seqs: 108,369, tokens: 27,270,908, loss: 2.589, total_acc: 55.42%, total_precision: 33.18%, total_recall: 22.54%, f1: 25.08%,  accs: 50.52%\n",
      "MB: 40500, seqs: 109,694, tokens: 27,612,977, loss: 2.270, total_acc: 57.36%, total_precision: 32.79%, total_recall: 20.86%, f1: 23.96%,  accs: 52.08%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.239, total_acc: [0.56537104], total_precision: [0.25918728], total_recall: [0.19939145], f1: [0.20412248], accs: 54.42%, distances: 17.636\n",
      "Step: 45\n",
      "MB: 41000, seqs: 111,032, tokens: 27,952,614, loss: 2.545, total_acc: 57.77%, total_precision: 35.83%, total_recall: 23.20%, f1: 26.33%,  accs: 52.69%\n",
      "MB: 41500, seqs: 112,442, tokens: 28,297,651, loss: 2.530, total_acc: 57.23%, total_precision: 36.81%, total_recall: 22.90%, f1: 26.72%,  accs: 52.91%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.281, total_acc: [0.5689046], total_precision: [0.2649909], total_recall: [0.21313308], f1: [0.21377052], accs: 54.42%, distances: 17.629\n",
      "Step: 46\n",
      "MB: 42000, seqs: 113,749, tokens: 28,636,528, loss: 2.424, total_acc: 57.23%, total_precision: 32.94%, total_recall: 22.75%, f1: 25.02%,  accs: 52.95%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.398, total_acc: [0.56183743], total_precision: [0.27414605], total_recall: [0.20447585], f1: [0.20865354], accs: 53.36%, distances: 17.749\n",
      "Step: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: 42500, seqs: 115,133, tokens: 28,978,961, loss: 2.253, total_acc: 59.25%, total_precision: 32.69%, total_recall: 21.61%, f1: 24.75%,  accs: 54.84%\n",
      "MB: 43000, seqs: 116,452, tokens: 29,317,352, loss: 2.445, total_acc: 58.23%, total_precision: 31.58%, total_recall: 21.82%, f1: 24.25%,  accs: 53.30%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.332, total_acc: [0.56183743], total_precision: [0.28599474], total_recall: [0.1811501], f1: [0.19882312], accs: 53.36%, distances: 17.671\n",
      "Step: 48\n",
      "MB: 43500, seqs: 117,803, tokens: 29,655,599, loss: 2.312, total_acc: 57.81%, total_precision: 36.57%, total_recall: 24.17%, f1: 27.50%,  accs: 52.78%\n",
      "MB: 44000, seqs: 119,175, tokens: 30,001,762, loss: 2.293, total_acc: 57.00%, total_precision: 35.27%, total_recall: 23.45%, f1: 26.37%,  accs: 52.41%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.253, total_acc: [0.56537104], total_precision: [0.27698362], total_recall: [0.19289361], f1: [0.20005436], accs: 54.77%, distances: 17.675\n",
      "Step: 49\n",
      "MB: 44500, seqs: 120,588, tokens: 30,344,323, loss: 2.408, total_acc: 55.91%, total_precision: 38.33%, total_recall: 24.37%, f1: 27.90%,  accs: 51.10%\n",
      "MB: 45000, seqs: 121,961, tokens: 30,685,379, loss: 2.353, total_acc: 57.68%, total_precision: 34.96%, total_recall: 23.03%, f1: 26.36%,  accs: 53.10%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.155, total_acc: [0.5724382], total_precision: [0.2621786], total_recall: [0.2419906], f1: [0.22752766], accs: 53.71%, distances: 17.470\n",
      "Step: 50\n",
      "MB: 45500, seqs: 123,259, tokens: 31,023,371, loss: 2.172, total_acc: 59.63%, total_precision: 35.69%, total_recall: 24.12%, f1: 27.59%,  accs: 55.08%\n",
      "MB: 46000, seqs: 124,629, tokens: 31,364,424, loss: 2.265, total_acc: 58.10%, total_precision: 37.92%, total_recall: 25.61%, f1: 28.65%,  accs: 53.07%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.174, total_acc: [0.5724382], total_precision: [0.28275284], total_recall: [0.22757025], f1: [0.22598015], accs: 53.36%, distances: 17.671\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -f True -m gnn --log gnn/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Restoring top model from step: 48\n",
      "Testing pre-trained model on full eval data\n",
      "{'batch_shape': [3, 390], 'correct_preds': [[1668, 1885]]}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': []}\n",
      "{'batch_shape': [5, 210], 'correct_preds': [[2035, 2264]]}\n",
      "{'batch_shape': [1, 650], 'correct_preds': []}\n",
      "{'batch_shape': [1, 757], 'correct_preds': [[1966, 2185]]}\n",
      "{'batch_shape': [3, 392], 'correct_preds': [[2604, 2865], [2102, 2330]]}\n",
      "{'batch_shape': [3, 338], 'correct_preds': [[1701, 1939], [2419, 2663], [1690, 1919]]}\n",
      "{'batch_shape': [4, 258], 'correct_preds': [[2410, 2648]]}\n",
      "{'batch_shape': [5, 239], 'correct_preds': [[2510, 2757], [2319, 2561]]}\n",
      "{'batch_shape': [11, 107], 'correct_preds': [[2021, 2237]]}\n",
      "{'batch_shape': [1, 642], 'correct_preds': []}\n",
      "{'batch_shape': [3, 379], 'correct_preds': [[1601, 1812], [1996, 2208], [1716, 1960]]}\n",
      "{'batch_shape': [2, 516], 'correct_preds': [[2378, 2615]]}\n",
      "{'batch_shape': [3, 327], 'correct_preds': []}\n",
      "{'batch_shape': [2, 538], 'correct_preds': [[1680, 1907]]}\n",
      "{'batch_shape': [1, 942], 'correct_preds': []}\n",
      "{'batch_shape': [2, 561], 'correct_preds': []}\n",
      "{'batch_shape': [10, 117], 'correct_preds': [[1667, 1884], [1724, 1967], [1649, 1865], [1655, 1871], [2883, 3145]]}\n",
      "{'batch_shape': [1, 776], 'correct_preds': [[1711, 1954]]}\n",
      "{'batch_shape': [3, 361], 'correct_preds': [[2249, 2482]]}\n",
      "{'batch_shape': [8, 144], 'correct_preds': [[2872, 3134], [2316, 2560], [2361, 2602], [2800, 3054], [2770, 3018]]}\n",
      "{'batch_shape': [17, 70], 'correct_preds': [[2924, 3193], [1995, 2208], [2894, 3162], [1660, 1877], [2081, 2307], [2183, 2414], [2656, 2921], [1676, 1896], [1965, 2185]]}\n",
      "{'batch_shape': [3, 322], 'correct_preds': [[2579, 2841]]}\n",
      "{'batch_shape': [2, 416], 'correct_preds': [[1699, 1930]]}\n",
      "{'batch_shape': [2, 549], 'correct_preds': [[1717, 1960]]}\n",
      "{'batch_shape': [21, 49], 'correct_preds': [[2581, 2847], [2792, 3046], [2768, 3013], [2705, 2964], [2792, 3045], [2705, 2965], [2227, 2458], [2803, 3058]]}\n",
      "{'batch_shape': [1, 778], 'correct_preds': [[1614, 1828]]}\n",
      "{'batch_shape': [1, 987], 'correct_preds': []}\n",
      "{'batch_shape': [1, 946], 'correct_preds': [[1826, 2067]]}\n",
      "{'batch_shape': [2, 451], 'correct_preds': [[1927, 2156]]}\n",
      "{'batch_shape': [9, 136], 'correct_preds': [[2446, 2691], [2593, 2855]]}\n",
      "{'batch_shape': [2, 479], 'correct_preds': [[1666, 1883]]}\n",
      "{'batch_shape': [1, 941], 'correct_preds': [[1926, 2156]]}\n",
      "{'batch_shape': [4, 287], 'correct_preds': [[2027, 2247]]}\n",
      "{'batch_shape': [3, 334], 'correct_preds': []}\n",
      "{'batch_shape': [5, 222], 'correct_preds': [[1708, 1953]]}\n",
      "{'batch_shape': [2, 585], 'correct_preds': []}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': [[1715, 1956]]}\n",
      "{'batch_shape': [1, 869], 'correct_preds': []}\n",
      "{'batch_shape': [2, 619], 'correct_preds': [[2416, 2662]]}\n",
      "{'batch_shape': [1, 855], 'correct_preds': [[2603, 2865]]}\n",
      "{'batch_shape': [3, 346], 'correct_preds': [[2664, 2929]]}\n",
      "{'batch_shape': [6, 186], 'correct_preds': [[1895, 2123], [2411, 2652], [1683, 1909]]}\n",
      "{'batch_shape': [4, 294], 'correct_preds': [[1674, 1893], [2144, 2373], [2243, 2475]]}\n",
      "{'batch_shape': [2, 509], 'correct_preds': [[2630, 2881]]}\n",
      "{'batch_shape': [3, 315], 'correct_preds': [[1675, 1895], [2767, 3012]]}\n",
      "{'batch_shape': [12, 102], 'correct_preds': [[1850, 2088], [2420, 2663], [2622, 2876]]}\n",
      "{'batch_shape': [6, 194], 'correct_preds': [[2502, 2746], [2320, 2563], [2557, 2816]]}\n",
      "{'batch_shape': [1, 706], 'correct_preds': []}\n",
      "{'batch_shape': [1, 775], 'correct_preds': []}\n",
      "{'batch_shape': [4, 271], 'correct_preds': [[2000, 2219], [2580, 2844]]}\n",
      "{'batch_shape': [7, 178], 'correct_preds': [[2599, 2860], [2984, 3262], [2864, 3126], [2605, 2865], [2441, 2688]]}\n",
      "{'batch_shape': [1, 949], 'correct_preds': [[1673, 1893]]}\n",
      "{'batch_shape': [2, 422], 'correct_preds': [[2523, 2772], [2930, 3198]]}\n",
      "{'batch_shape': [5, 225], 'correct_preds': [[1664, 1883], [2844, 3114], [2140, 2370]]}\n",
      "{'batch_shape': [2, 429], 'correct_preds': []}\n",
      "{'batch_shape': [2, 526], 'correct_preds': []}\n",
      "{'batch_shape': [1, 630], 'correct_preds': []}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [5, 238], 'correct_preds': [[2632, 2884], [1677, 1901], [3038, 3312]]}\n",
      "{'batch_shape': [1, 641], 'correct_preds': [[2606, 2865]]}\n",
      "{'batch_shape': [1, 659], 'correct_preds': [[1679, 1904]]}\n",
      "{'batch_shape': [2, 548], 'correct_preds': [[1718, 1960]]}\n",
      "{'batch_shape': [2, 503], 'correct_preds': [[1928, 2156], [2105, 2338]]}\n",
      "{'batch_shape': [1, 645], 'correct_preds': []}\n",
      "{'batch_shape': [4, 303], 'correct_preds': [[1665, 1883]]}\n",
      "{'batch_shape': [1, 655], 'correct_preds': [[2348, 2582]]}\n",
      "{'batch_shape': [1, 951], 'correct_preds': []}\n",
      "{'batch_shape': [5, 155], 'correct_preds': [[2617, 2870], [2883, 3144], [2227, 2456]]}\n",
      "{'batch_shape': [1, 977], 'correct_preds': []}\n",
      "{'batch_shape': [2, 533], 'correct_preds': [[1684, 1911]]}\n",
      "{'batch_shape': [2, 561], 'correct_preds': []}\n",
      "{'batch_shape': [2, 461], 'correct_preds': [[1725, 1970], [2684, 2945]]}\n",
      "{'batch_shape': [1, 637], 'correct_preds': []}\n",
      "{'batch_shape': [3, 351], 'correct_preds': [[1960, 2179]]}\n",
      "{'batch_shape': [2, 533], 'correct_preds': []}\n",
      "{'batch_shape': [1, 693], 'correct_preds': [[1840, 2080]]}\n",
      "{'batch_shape': [1, 697], 'correct_preds': []}\n",
      "{'batch_shape': [4, 308], 'correct_preds': [[1560, 1771], [2223, 2450]]}\n",
      "{'batch_shape': [1, 628], 'correct_preds': [[1676, 1895]]}\n",
      "{'batch_shape': [1, 644], 'correct_preds': []}\n",
      "{'batch_shape': [1, 665], 'correct_preds': [[1682, 1909]]}\n",
      "{'batch_shape': [2, 492], 'correct_preds': [[1997, 2208]]}\n",
      "{'batch_shape': [1, 605], 'correct_preds': []}\n",
      "{'batch_shape': [1, 667], 'correct_preds': []}\n",
      "{'batch_shape': [1, 698], 'correct_preds': []}\n",
      "{'batch_shape': [1, 803], 'correct_preds': [[2440, 2688]]}\n",
      "{'batch_shape': [1, 670], 'correct_preds': [[1588, 1800]]}\n",
      "{'batch_shape': [1, 630], 'correct_preds': [[2918, 3182]]}\n",
      "{'batch_shape': [1, 991], 'correct_preds': []}\n",
      "{'batch_shape': [3, 344], 'correct_preds': [[1728, 1974], [2181, 2414], [2529, 2775]]}\n",
      "{'batch_shape': [2, 436], 'correct_preds': [[2165, 2395]]}\n",
      "{'batch_shape': [1, 918], 'correct_preds': []}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [1, 833], 'correct_preds': [[2387, 2626]]}\n",
      "{'batch_shape': [1, 752], 'correct_preds': []}\n",
      "{'batch_shape': [1, 684], 'correct_preds': [[1581, 1793]]}\n",
      "{'batch_shape': [1, 894], 'correct_preds': [[2299, 2531]]}\n",
      "{'batch_shape': [1, 971], 'correct_preds': []}\n",
      "{'batch_shape': [1, 977], 'correct_preds': [[1686, 1916]]}\n",
      "{'batch_shape': [1, 636], 'correct_preds': []}\n",
      "{'batch_shape': [1, 896], 'correct_preds': [[1669, 1890]]}\n",
      "{'batch_shape': [1, 668], 'correct_preds': []}\n",
      "{'batch_shape': [1, 682], 'correct_preds': [[2727, 2989]]}\n",
      "Evaluation result: seqs: 288, tokens: 63,797, loss: 4.110, total_acc: [0.48958334], total_precision: [0.3449074], total_recall: [0.18397816], f1: [0.2116451], accs: 43.75%, distances: 16.410\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -e True -m finetune_gnn --log finetune_gnn/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Model initialized, training 9,457,921 parameters\n",
      "Restoring top model from step: 10\n",
      "Restored from step: 11\n",
      "MB: 500, seqs: 1,541, tokens: 350,559, loss: 4.384, total_acc: 48.60%, total_precision: 1.54%, total_recall: 0.85%, f1: 0.98%,  accs: 48.80%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.602, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 2\n",
      "MB: 1000, seqs: 2,891, tokens: 691,098, loss: 4.003, total_acc: 45.41%, total_precision: 1.11%, total_recall: 0.19%, f1: 0.32%,  accs: 45.33%\n",
      "MB: 1500, seqs: 4,267, tokens: 1,033,094, loss: 3.666, total_acc: 49.13%, total_precision: 1.02%, total_recall: 0.13%, f1: 0.23%,  accs: 49.06%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.693, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 3\n",
      "MB: 2000, seqs: 5,650, tokens: 1,373,434, loss: 3.873, total_acc: 50.69%, total_precision: 1.81%, total_recall: 0.34%, f1: 0.56%,  accs: 50.61%\n",
      "MB: 2500, seqs: 7,030, tokens: 1,718,508, loss: 3.764, total_acc: 48.91%, total_precision: 0.00%, total_recall: 0.00%, f1: 0.00%,  accs: 48.91%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.893, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 4\n",
      "MB: 3000, seqs: 8,348, tokens: 2,054,479, loss: 3.840, total_acc: 49.09%, total_precision: 2.05%, total_recall: 0.40%, f1: 0.66%,  accs: 49.09%\n",
      "MB: 3500, seqs: 9,685, tokens: 2,395,907, loss: 3.916, total_acc: 46.22%, total_precision: 0.00%, total_recall: 0.00%, f1: 0.00%,  accs: 46.22%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.296, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 5\n",
      "MB: 4000, seqs: 10,992, tokens: 2,734,987, loss: 3.778, total_acc: 49.27%, total_precision: 3.60%, total_recall: 0.68%, f1: 1.13%,  accs: 49.20%\n",
      "MB: 4500, seqs: 12,363, tokens: 3,075,217, loss: 3.913, total_acc: 47.92%, total_precision: 2.48%, total_recall: 0.70%, f1: 1.07%,  accs: 47.70%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.745, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 6\n",
      "MB: 5000, seqs: 13,739, tokens: 3,415,777, loss: 3.765, total_acc: 49.56%, total_precision: 3.63%, total_recall: 0.69%, f1: 1.12%,  accs: 49.35%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.716, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 7\n",
      "MB: 5500, seqs: 15,067, tokens: 3,757,330, loss: 3.630, total_acc: 48.12%, total_precision: 1.13%, total_recall: 0.40%, f1: 0.57%,  accs: 48.19%\n",
      "MB: 6000, seqs: 16,458, tokens: 4,103,703, loss: 3.633, total_acc: 49.75%, total_precision: 4.85%, total_recall: 0.81%, f1: 1.35%,  accs: 49.60%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.941, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 8\n",
      "MB: 6500, seqs: 17,879, tokens: 4,445,248, loss: 3.819, total_acc: 47.15%, total_precision: 2.53%, total_recall: 0.41%, f1: 0.69%,  accs: 47.08%\n",
      "MB: 7000, seqs: 19,184, tokens: 4,782,463, loss: 3.891, total_acc: 48.05%, total_precision: 1.86%, total_recall: 0.45%, f1: 0.67%,  accs: 48.05%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.016, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 9\n",
      "MB: 7500, seqs: 20,490, tokens: 5,121,050, loss: 3.723, total_acc: 48.62%, total_precision: 0.00%, total_recall: 0.00%, f1: 0.00%,  accs: 48.62%\n",
      "MB: 8000, seqs: 21,915, tokens: 5,463,558, loss: 3.682, total_acc: 49.54%, total_precision: 3.56%, total_recall: 1.30%, f1: 1.70%,  accs: 49.47%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.890, total_acc: [0.5017668], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 10\n",
      "MB: 8500, seqs: 23,237, tokens: 5,801,244, loss: 3.700, total_acc: 47.96%, total_precision: 2.04%, total_recall: 0.41%, f1: 0.68%,  accs: 47.81%\n",
      "MB: 9000, seqs: 24,548, tokens: 6,140,716, loss: 3.750, total_acc: 47.90%, total_precision: 1.60%, total_recall: 0.33%, f1: 0.53%,  accs: 47.90%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.471, total_acc: [0.50530034], total_precision: [0.03533569], total_recall: [0.007067138], f1: [0.011778563], accs: 50.53%, distances: 18.406\n",
      "Step: 11\n",
      "MB: 9500, seqs: 25,895, tokens: 6,482,488, loss: 3.953, total_acc: 48.55%, total_precision: 3.86%, total_recall: 1.29%, f1: 1.73%,  accs: 48.48%\n",
      "MB: 10000, seqs: 27,274, tokens: 6,825,405, loss: 3.772, total_acc: 48.51%, total_precision: 2.10%, total_recall: 0.34%, f1: 0.58%,  accs: 48.44%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.491, total_acc: [0.5017668], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 12\n",
      "MB: 10500, seqs: 28,618, tokens: 7,168,234, loss: 3.811, total_acc: 48.96%, total_precision: 5.21%, total_recall: 1.02%, f1: 1.68%,  accs: 48.88%\n",
      "MB: 11000, seqs: 30,000, tokens: 7,507,333, loss: 3.819, total_acc: 47.11%, total_precision: 7.72%, total_recall: 1.30%, f1: 2.16%,  accs: 46.89%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.774, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 13\n",
      "MB: 11500, seqs: 31,359, tokens: 7,850,934, loss: 3.818, total_acc: 48.64%, total_precision: 4.93%, total_recall: 0.89%, f1: 1.50%,  accs: 48.57%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.760, total_acc: [0.5017668], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 14\n",
      "MB: 12000, seqs: 32,733, tokens: 8,191,540, loss: 3.785, total_acc: 48.54%, total_precision: 2.26%, total_recall: 0.45%, f1: 0.73%,  accs: 48.69%\n",
      "MB: 12500, seqs: 34,043, tokens: 8,531,411, loss: 3.818, total_acc: 47.40%, total_precision: 4.66%, total_recall: 1.05%, f1: 1.64%,  accs: 47.33%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.853, total_acc: [0.50530034], total_precision: [0.056537103], total_recall: [0.0062819], f1: [0.01130742], accs: 50.53%, distances: 18.396\n",
      "Step: 15\n",
      "MB: 13000, seqs: 35,398, tokens: 8,873,329, loss: 3.663, total_acc: 49.67%, total_precision: 6.96%, total_recall: 2.15%, f1: 3.10%,  accs: 49.08%\n",
      "MB: 13500, seqs: 36,714, tokens: 9,209,319, loss: 3.717, total_acc: 49.62%, total_precision: 7.14%, total_recall: 1.21%, f1: 2.02%,  accs: 49.32%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.609, total_acc: [0.50883394], total_precision: [0.0795053], total_recall: [0.013898704], f1: [0.0218227], accs: 50.88%, distances: 18.371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16\n",
      "MB: 14000, seqs: 38,084, tokens: 9,549,707, loss: 3.709, total_acc: 50.88%, total_precision: 9.09%, total_recall: 2.94%, f1: 4.10%,  accs: 50.07%\n",
      "MB: 14500, seqs: 39,440, tokens: 9,893,838, loss: 3.777, total_acc: 47.71%, total_precision: 11.30%, total_recall: 2.81%, f1: 4.18%,  accs: 47.05%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.753, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 17\n",
      "MB: 15000, seqs: 40,799, tokens: 10,235,473, loss: 3.628, total_acc: 49.30%, total_precision: 1.20%, total_recall: 0.37%, f1: 0.52%,  accs: 49.23%\n",
      "MB: 15500, seqs: 42,135, tokens: 10,572,038, loss: 3.645, total_acc: 48.58%, total_precision: 4.44%, total_recall: 0.90%, f1: 1.37%,  accs: 48.50%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.816, total_acc: [0.5017668], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 18\n",
      "MB: 16000, seqs: 43,493, tokens: 10,915,701, loss: 3.888, total_acc: 46.54%, total_precision: 5.94%, total_recall: 1.26%, f1: 2.06%,  accs: 46.24%\n",
      "MB: 16500, seqs: 44,841, tokens: 11,256,380, loss: 3.599, total_acc: 48.15%, total_precision: 2.92%, total_recall: 0.94%, f1: 1.26%,  accs: 48.00%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.603, total_acc: [0.50883394], total_precision: [0.08127209], total_recall: [0.012064614], f1: [0.020344792], accs: 50.88%, distances: 18.371\n",
      "Step: 19\n",
      "MB: 17000, seqs: 46,171, tokens: 11,600,136, loss: 3.700, total_acc: 48.65%, total_precision: 2.66%, total_recall: 0.89%, f1: 1.25%,  accs: 48.35%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.713, total_acc: [0.50530034], total_precision: [0.021201413], total_recall: [0.008480566], f1: [0.012115095], accs: 50.88%, distances: 18.382\n",
      "Step: 20\n",
      "MB: 17500, seqs: 47,554, tokens: 11,940,859, loss: 3.647, total_acc: 48.88%, total_precision: 4.48%, total_recall: 1.31%, f1: 1.90%,  accs: 48.66%\n",
      "MB: 18000, seqs: 48,888, tokens: 12,280,451, loss: 3.701, total_acc: 48.80%, total_precision: 10.44%, total_recall: 2.58%, f1: 4.01%,  accs: 48.13%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.106, total_acc: [0.50883394], total_precision: [0.08480565], total_recall: [0.03215548], f1: [0.045791842], accs: 50.18%, distances: 18.357\n",
      "Step: 21\n",
      "MB: 18500, seqs: 50,237, tokens: 12,619,930, loss: 3.564, total_acc: 51.00%, total_precision: 8.44%, total_recall: 2.17%, f1: 3.32%,  accs: 50.11%\n",
      "MB: 19000, seqs: 51,604, tokens: 12,959,014, loss: 3.286, total_acc: 52.08%, total_precision: 8.94%, total_recall: 2.12%, f1: 3.24%,  accs: 51.43%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.912, total_acc: [0.50883394], total_precision: [0.03533569], total_recall: [0.0050479556], f1: [0.008833922], accs: 50.88%, distances: 18.382\n",
      "Step: 22\n",
      "MB: 19500, seqs: 52,954, tokens: 13,297,184, loss: 3.588, total_acc: 49.41%, total_precision: 4.07%, total_recall: 1.49%, f1: 2.07%,  accs: 49.26%\n",
      "MB: 20000, seqs: 54,293, tokens: 13,638,902, loss: 3.949, total_acc: 46.38%, total_precision: 8.70%, total_recall: 2.66%, f1: 3.85%,  accs: 45.63%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.733, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 23\n",
      "MB: 20500, seqs: 55,661, tokens: 13,984,503, loss: 3.637, total_acc: 46.71%, total_precision: 7.46%, total_recall: 1.66%, f1: 2.62%,  accs: 46.56%\n",
      "MB: 21000, seqs: 56,993, tokens: 14,326,101, loss: 3.573, total_acc: 51.13%, total_precision: 12.94%, total_recall: 4.71%, f1: 6.24%,  accs: 50.15%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.689, total_acc: [0.50883394], total_precision: [0.045936394], total_recall: [0.009187279], f1: [0.015312132], accs: 50.88%, distances: 18.382\n",
      "Step: 24\n",
      "MB: 21500, seqs: 58,330, tokens: 14,662,378, loss: 3.652, total_acc: 50.93%, total_precision: 12.75%, total_recall: 3.22%, f1: 4.80%,  accs: 49.74%\n",
      "MB: 22000, seqs: 59,699, tokens: 15,007,775, loss: 3.717, total_acc: 48.14%, total_precision: 4.75%, total_recall: 1.18%, f1: 1.80%,  accs: 47.85%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.730, total_acc: [0.50883394], total_precision: [0.042402826], total_recall: [0.004240283], f1: [0.007709605], accs: 50.88%, distances: 18.382\n",
      "Step: 25\n",
      "MB: 22500, seqs: 61,045, tokens: 15,347,124, loss: 3.426, total_acc: 51.26%, total_precision: 5.35%, total_recall: 1.95%, f1: 2.72%,  accs: 51.04%\n",
      "MB: 23000, seqs: 62,379, tokens: 15,684,813, loss: 3.806, total_acc: 48.95%, total_precision: 14.27%, total_recall: 4.30%, f1: 6.26%,  accs: 47.68%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.684, total_acc: [0.50883394], total_precision: [0.13427562], total_recall: [0.019434629], f1: [0.03363774], accs: 50.88%, distances: 18.339\n",
      "Step: 26\n",
      "MB: 23500, seqs: 63,728, tokens: 16,025,749, loss: 3.575, total_acc: 49.30%, total_precision: 9.34%, total_recall: 2.64%, f1: 3.88%,  accs: 48.70%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.807, total_acc: [0.49823323], total_precision: [0.07714959], total_recall: [0.018109541], f1: [0.028964559], accs: 50.18%, distances: 18.360\n",
      "Step: 27\n",
      "MB: 24000, seqs: 65,088, tokens: 16,367,240, loss: 3.565, total_acc: 49.34%, total_precision: 8.00%, total_recall: 2.40%, f1: 3.54%,  accs: 48.90%\n",
      "MB: 24500, seqs: 66,466, tokens: 16,713,429, loss: 3.665, total_acc: 48.69%, total_precision: 9.41%, total_recall: 3.23%, f1: 4.68%,  accs: 47.82%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.816, total_acc: [0.5159011], total_precision: [0.13074204], total_recall: [0.019980727], f1: [0.034157835], accs: 51.24%, distances: 18.325\n",
      "Step: 28\n",
      "MB: 25000, seqs: 67,827, tokens: 17,054,174, loss: 3.465, total_acc: 50.62%, total_precision: 8.28%, total_recall: 2.58%, f1: 3.77%,  accs: 49.82%\n",
      "MB: 25500, seqs: 69,210, tokens: 17,397,397, loss: 3.652, total_acc: 48.52%, total_precision: 10.15%, total_recall: 3.04%, f1: 4.57%,  accs: 47.72%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.742, total_acc: [0.50530034], total_precision: [0.0], total_recall: [0.0], f1: [0.0], accs: 50.53%, distances: 18.406\n",
      "Step: 29\n",
      "MB: 26000, seqs: 70,598, tokens: 17,738,369, loss: 3.478, total_acc: 47.41%, total_precision: 7.88%, total_recall: 1.83%, f1: 2.85%,  accs: 46.97%\n",
      "MB: 26500, seqs: 71,908, tokens: 18,077,079, loss: 3.497, total_acc: 50.84%, total_precision: 10.52%, total_recall: 4.53%, f1: 5.79%,  accs: 50.00%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.693, total_acc: [0.5123675], total_precision: [0.077738516], total_recall: [0.015547704], f1: [0.02591284], accs: 50.88%, distances: 18.346\n",
      "Step: 30\n",
      "MB: 27000, seqs: 73,264, tokens: 18,417,787, loss: 3.616, total_acc: 49.85%, total_precision: 10.63%, total_recall: 2.97%, f1: 4.45%,  accs: 49.19%\n",
      "MB: 27500, seqs: 74,608, tokens: 18,757,541, loss: 3.568, total_acc: 49.11%, total_precision: 11.55%, total_recall: 3.31%, f1: 4.91%,  accs: 47.92%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.910, total_acc: [0.50883394], total_precision: [0.11778564], total_recall: [0.043816257], f1: [0.060523696], accs: 50.53%, distances: 18.322\n",
      "Step: 31\n",
      "MB: 28000, seqs: 75,945, tokens: 19,098,549, loss: 3.612, total_acc: 51.38%, total_precision: 12.57%, total_recall: 4.92%, f1: 6.74%,  accs: 49.81%\n",
      "MB: 28500, seqs: 77,325, tokens: 19,443,843, loss: 3.572, total_acc: 50.07%, total_precision: 15.73%, total_recall: 4.25%, f1: 6.30%,  accs: 49.28%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.921, total_acc: [0.50883394], total_precision: [0.14016491], total_recall: [0.026737338], f1: [0.0418292], accs: 50.88%, distances: 18.304\n",
      "Step: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: 29000, seqs: 78,647, tokens: 19,782,003, loss: 3.475, total_acc: 50.08%, total_precision: 6.27%, total_recall: 2.05%, f1: 2.96%,  accs: 49.55%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.002, total_acc: [0.5123675], total_precision: [0.14487633], total_recall: [0.026383983], f1: [0.043091185], accs: 50.88%, distances: 18.346\n",
      "Step: 33\n",
      "MB: 29500, seqs: 80,036, tokens: 20,122,268, loss: 3.628, total_acc: 50.04%, total_precision: 16.77%, total_recall: 6.04%, f1: 8.15%,  accs: 48.67%\n",
      "MB: 30000, seqs: 81,388, tokens: 20,464,819, loss: 3.302, total_acc: 51.33%, total_precision: 12.48%, total_recall: 5.30%, f1: 7.14%,  accs: 50.37%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.662, total_acc: [0.5159011], total_precision: [0.14899883], total_recall: [0.0497448], f1: [0.071772754], accs: 50.88%, distances: 18.286\n",
      "Step: 34\n",
      "MB: 30500, seqs: 82,691, tokens: 20,802,841, loss: 3.693, total_acc: 48.27%, total_precision: 11.36%, total_recall: 4.90%, f1: 6.59%,  accs: 46.82%\n",
      "MB: 31000, seqs: 84,037, tokens: 21,142,338, loss: 3.437, total_acc: 50.07%, total_precision: 11.04%, total_recall: 2.82%, f1: 4.25%,  accs: 49.03%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.538, total_acc: [0.5229682], total_precision: [0.20141342], total_recall: [0.04941107], f1: [0.0748933], accs: 50.53%, distances: 18.240\n",
      "Step: 35\n",
      "MB: 31500, seqs: 85,409, tokens: 21,484,979, loss: 3.557, total_acc: 50.87%, total_precision: 12.59%, total_recall: 5.21%, f1: 6.80%,  accs: 49.78%\n",
      "MB: 32000, seqs: 86,773, tokens: 21,824,862, loss: 3.512, total_acc: 51.17%, total_precision: 16.05%, total_recall: 5.70%, f1: 7.66%,  accs: 49.71%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.908, total_acc: [0.5300353], total_precision: [0.21201414], total_recall: [0.06342757], f1: [0.090255916], accs: 50.88%, distances: 18.286\n",
      "Step: 36\n",
      "MB: 32500, seqs: 88,128, tokens: 22,166,137, loss: 3.645, total_acc: 48.93%, total_precision: 16.13%, total_recall: 7.33%, f1: 9.55%,  accs: 47.68%\n",
      "MB: 33000, seqs: 89,466, tokens: 22,503,797, loss: 3.302, total_acc: 50.45%, total_precision: 13.21%, total_recall: 5.18%, f1: 6.88%,  accs: 49.33%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.145, total_acc: [0.5229682], total_precision: [0.19081272], total_recall: [0.059830897], f1: [0.0861602], accs: 50.88%, distances: 18.286\n",
      "Step: 37\n",
      "MB: 33500, seqs: 90,801, tokens: 22,843,208, loss: 3.305, total_acc: 51.16%, total_precision: 13.47%, total_recall: 5.51%, f1: 7.39%,  accs: 50.04%\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -f True -m transformer --log transformer/log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grazia\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (5.1.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Model initialized, training 9,457,921 parameters\n",
      "Restoring top model from step: 10\n",
      "Restored from step: 11\n",
      "Begin fine tuning from step : 37\n",
      "MB: 500, seqs: 91,559, tokens: 349,477, loss: 3.332, total_acc: 49.87%, total_precision: 16.16%, total_recall: 6.25%, f1: 8.40%,  accs: 48.07%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.705, total_acc: [0.5229682], total_precision: [0.20141342], total_recall: [0.07249706], f1: [0.10513209], accs: 50.53%, distances: 18.297\n",
      "Step: 38\n",
      "MB: 1000, seqs: 92,933, tokens: 691,221, loss: 3.395, total_acc: 50.80%, total_precision: 17.20%, total_recall: 7.33%, f1: 9.64%,  accs: 48.84%\n",
      "MB: 1500, seqs: 94,302, tokens: 1,034,248, loss: 3.370, total_acc: 50.18%, total_precision: 11.37%, total_recall: 4.99%, f1: 6.58%,  accs: 49.38%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.014, total_acc: [0.51943463], total_precision: [0.17491166], total_recall: [0.06207303], f1: [0.08392226], accs: 50.53%, distances: 18.297\n",
      "Step: 39\n",
      "MB: 2000, seqs: 95,649, tokens: 1,373,111, loss: 3.231, total_acc: 54.05%, total_precision: 13.00%, total_recall: 5.77%, f1: 7.55%,  accs: 52.34%\n",
      "MB: 2500, seqs: 97,019, tokens: 1,713,919, loss: 3.515, total_acc: 51.17%, total_precision: 18.57%, total_recall: 7.87%, f1: 10.20%,  accs: 48.98%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.896, total_acc: [0.51943463], total_precision: [0.124263845], total_recall: [0.04996074], f1: [0.070028916], accs: 51.24%, distances: 18.300\n",
      "Step: 40\n",
      "MB: 3000, seqs: 98,357, tokens: 2,054,350, loss: 3.426, total_acc: 49.55%, total_precision: 14.44%, total_recall: 4.59%, f1: 6.64%,  accs: 48.36%\n",
      "MB: 3500, seqs: 99,683, tokens: 2,395,570, loss: 3.505, total_acc: 51.36%, total_precision: 14.95%, total_recall: 6.51%, f1: 8.50%,  accs: 50.00%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.752, total_acc: [0.5229682], total_precision: [0.15783274], total_recall: [0.086631335], f1: [0.10718493], accs: 52.30%, distances: 18.173\n",
      "Step: 41\n",
      "MB: 4000, seqs: 101,018, tokens: 2,733,262, loss: 3.344, total_acc: 50.56%, total_precision: 14.86%, total_recall: 5.75%, f1: 7.90%,  accs: 49.29%\n",
      "MB: 4500, seqs: 102,343, tokens: 3,075,280, loss: 3.418, total_acc: 50.94%, total_precision: 14.20%, total_recall: 5.89%, f1: 7.89%,  accs: 49.81%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.009, total_acc: [0.5265018], total_precision: [0.24558304], total_recall: [0.057979982], f1: [0.091670886], accs: 50.88%, distances: 18.311\n",
      "Step: 42\n",
      "MB: 5000, seqs: 103,743, tokens: 3,413,872, loss: 3.516, total_acc: 51.07%, total_precision: 18.95%, total_recall: 6.00%, f1: 8.59%,  accs: 49.71%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.956, total_acc: [0.51943463], total_precision: [0.17432274], total_recall: [0.04018173], f1: [0.062819004], accs: 51.59%, distances: 18.251\n",
      "Step: 43\n",
      "MB: 5500, seqs: 105,076, tokens: 3,754,752, loss: 3.375, total_acc: 50.86%, total_precision: 13.16%, total_recall: 5.43%, f1: 7.20%,  accs: 48.99%\n",
      "MB: 6000, seqs: 106,497, tokens: 4,101,982, loss: 3.156, total_acc: 53.41%, total_precision: 18.82%, total_recall: 8.80%, f1: 11.38%,  accs: 51.23%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.799, total_acc: [0.53710246], total_precision: [0.20129564], total_recall: [0.14452298], f1: [0.15812653], accs: 51.94%, distances: 18.159\n",
      "Step: 44\n",
      "MB: 6500, seqs: 107,886, tokens: 4,442,935, loss: 3.360, total_acc: 51.26%, total_precision: 19.54%, total_recall: 9.21%, f1: 11.56%,  accs: 48.67%\n",
      "MB: 7000, seqs: 109,174, tokens: 4,778,865, loss: 3.320, total_acc: 53.11%, total_precision: 19.23%, total_recall: 9.52%, f1: 12.13%,  accs: 50.47%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.564, total_acc: [0.51943463], total_precision: [0.18404005], total_recall: [0.08751472], f1: [0.112413384], accs: 51.59%, distances: 18.269\n",
      "Step: 45\n",
      "MB: 7500, seqs: 110,487, tokens: 5,120,028, loss: 3.342, total_acc: 50.57%, total_precision: 14.74%, total_recall: 4.76%, f1: 6.91%,  accs: 48.90%\n",
      "MB: 8000, seqs: 111,886, tokens: 5,460,751, loss: 3.324, total_acc: 50.39%, total_precision: 16.47%, total_recall: 8.35%, f1: 10.43%,  accs: 49.04%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.852, total_acc: [0.5159011], total_precision: [0.16890459], total_recall: [0.062317017], f1: [0.084410235], accs: 50.88%, distances: 18.244\n",
      "Step: 46\n",
      "MB: 8500, seqs: 113,258, tokens: 5,803,515, loss: 3.414, total_acc: 52.04%, total_precision: 17.97%, total_recall: 8.59%, f1: 11.02%,  accs: 49.78%\n",
      "MB: 9000, seqs: 114,577, tokens: 6,141,461, loss: 3.311, total_acc: 52.31%, total_precision: 16.77%, total_recall: 7.33%, f1: 9.63%,  accs: 50.64%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.763, total_acc: [0.5229682], total_precision: [0.23144877], total_recall: [0.05266089], f1: [0.083038874], accs: 51.24%, distances: 18.272\n",
      "Step: 47\n",
      "MB: 9500, seqs: 115,887, tokens: 6,482,708, loss: 3.447, total_acc: 51.68%, total_precision: 16.86%, total_recall: 9.17%, f1: 11.22%,  accs: 49.62%\n",
      "MB: 10000, seqs: 117,251, tokens: 6,827,841, loss: 3.317, total_acc: 52.20%, total_precision: 22.49%, total_recall: 10.14%, f1: 13.33%,  accs: 49.19%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.826, total_acc: [0.5265018], total_precision: [0.16607775], total_recall: [0.09115767], f1: [0.11363968], accs: 51.59%, distances: 18.254\n",
      "Step: 48\n",
      "MB: 10500, seqs: 118,616, tokens: 7,165,406, loss: 3.254, total_acc: 54.29%, total_precision: 20.23%, total_recall: 9.93%, f1: 12.26%,  accs: 51.65%\n",
      "MB: 11000, seqs: 119,991, tokens: 7,504,403, loss: 3.210, total_acc: 50.62%, total_precision: 18.67%, total_recall: 8.06%, f1: 10.59%,  accs: 48.73%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 3.971, total_acc: [0.5335689], total_precision: [0.17196703], total_recall: [0.0942285], f1: [0.12034327], accs: 52.30%, distances: 18.194\n",
      "Step: 49\n",
      "MB: 11500, seqs: 121,328, tokens: 7,846,437, loss: 3.207, total_acc: 52.43%, total_precision: 15.58%, total_recall: 7.42%, f1: 9.50%,  accs: 50.71%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.118, total_acc: [0.53710246], total_precision: [0.20247349], total_recall: [0.1319788], f1: [0.1456896], accs: 51.94%, distances: 18.237\n",
      "Step: 50\n",
      "MB: 12000, seqs: 122,702, tokens: 8,187,848, loss: 3.187, total_acc: 52.33%, total_precision: 22.02%, total_recall: 12.58%, f1: 14.88%,  accs: 48.98%\n",
      "MB: 12500, seqs: 124,039, tokens: 8,527,991, loss: 3.434, total_acc: 51.76%, total_precision: 18.20%, total_recall: 9.06%, f1: 11.55%,  accs: 49.14%\n",
      "Running evaluation pass on heldout data\n",
      "Evaluation result: seqs: 283, tokens: 72,757, loss: 4.121, total_acc: [0.5265018], total_precision: [0.14840989], total_recall: [0.0751865], f1: [0.09553651], accs: 52.30%, distances: 18.177\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -f True -m transformer --log transformer/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Restoring top model from step: 40\n",
      "Testing pre-trained model on full eval data\n",
      "{'batch_shape': [6, 202], 'correct_preds': [[1895, 2123], [1683, 1909]]}\n",
      "{'batch_shape': [4, 271], 'correct_preds': [[1728, 1974], [2000, 2219]]}\n",
      "{'batch_shape': [3, 392], 'correct_preds': [[1668, 1885], [2102, 2330]]}\n",
      "{'batch_shape': [18, 68], 'correct_preds': [[1671, 1892], [1693, 1922], [1704, 1945], [1709, 1953], [1722, 1966], [1965, 2185], [1649, 1866], [1716, 1957], [1882, 2115], [1995, 2208], [1694, 1923]]}\n",
      "{'batch_shape': [2, 535], 'correct_preds': [[1684, 1911]]}\n",
      "{'batch_shape': [1, 641], 'correct_preds': [[2606, 2865]]}\n",
      "{'batch_shape': [1, 894], 'correct_preds': [[2299, 2531]]}\n",
      "{'batch_shape': [14, 87], 'correct_preds': [[2913, 3181], [2894, 3162], [2081, 2307], [2183, 2414], [2656, 2921], [2705, 2964], [2792, 3045], [2617, 2869]]}\n",
      "{'batch_shape': [5, 239], 'correct_preds': [[2319, 2561], [2510, 2757]]}\n",
      "{'batch_shape': [13, 91], 'correct_preds': [[2705, 2965], [2768, 3013], [2803, 3059], [2792, 3046], [2581, 2847], [2803, 3058], [2987, 3266], [2924, 3193]]}\n",
      "{'batch_shape': [3, 315], 'correct_preds': [[2767, 3012], [1675, 1895]]}\n",
      "{'batch_shape': [12, 102], 'correct_preds': [[1850, 2088], [2420, 2663], [2622, 2876]]}\n",
      "{'batch_shape': [4, 287], 'correct_preds': []}\n",
      "{'batch_shape': [1, 918], 'correct_preds': []}\n",
      "{'batch_shape': [1, 951], 'correct_preds': []}\n",
      "{'batch_shape': [4, 274], 'correct_preds': [[2181, 2414], [2580, 2844]]}\n",
      "{'batch_shape': [1, 855], 'correct_preds': [[2603, 2865]]}\n",
      "{'batch_shape': [3, 322], 'correct_preds': [[2579, 2841]]}\n",
      "{'batch_shape': [2, 548], 'correct_preds': [[1718, 1960]]}\n",
      "{'batch_shape': [4, 303], 'correct_preds': [[1665, 1883]]}\n",
      "{'batch_shape': [7, 163], 'correct_preds': [[2883, 3144], [2441, 2688], [2605, 2865]]}\n",
      "{'batch_shape': [5, 221], 'correct_preds': [[2844, 3114], [1708, 1953]]}\n",
      "{'batch_shape': [6, 181], 'correct_preds': [[2599, 2860], [2984, 3262], [2632, 2884]]}\n",
      "{'batch_shape': [1, 778], 'correct_preds': [[1614, 1828]]}\n",
      "{'batch_shape': [5, 228], 'correct_preds': [[2140, 2370], [1677, 1901], [1664, 1883]]}\n",
      "{'batch_shape': [8, 144], 'correct_preds': [[2872, 3134], [2316, 2560], [2800, 3054], [2361, 2602]]}\n",
      "{'batch_shape': [11, 112], 'correct_preds': [[2021, 2237], [1667, 1884], [1724, 1967]]}\n",
      "{'batch_shape': [3, 363], 'correct_preds': [[2249, 2482]]}\n",
      "{'batch_shape': [9, 132], 'correct_preds': [[2446, 2691], [2055, 2282], [2593, 2855], [2800, 3056]]}\n",
      "{'batch_shape': [3, 338], 'correct_preds': [[1701, 1939], [2419, 2663], [3027, 3303]]}\n",
      "{'batch_shape': [3, 308], 'correct_preds': [[2223, 2450], [1560, 1771], [2243, 2475]]}\n",
      "{'batch_shape': [6, 183], 'correct_preds': [[1649, 1865], [1655, 1871]]}\n",
      "{'batch_shape': [1, 946], 'correct_preds': [[1826, 2067]]}\n",
      "{'batch_shape': [1, 684], 'correct_preds': [[1581, 1793]]}\n",
      "{'batch_shape': [3, 351], 'correct_preds': [[1960, 2179]]}\n",
      "{'batch_shape': [2, 526], 'correct_preds': []}\n",
      "{'batch_shape': [6, 199], 'correct_preds': [[2502, 2746], [2320, 2563], [2557, 2816], [2791, 3045], [2411, 2652]]}\n",
      "{'batch_shape': [2, 549], 'correct_preds': [[1717, 1960]]}\n",
      "{'batch_shape': [2, 422], 'correct_preds': [[2523, 2772], [2930, 3198]]}\n",
      "{'batch_shape': [3, 346], 'correct_preds': [[2664, 2929]]}\n",
      "{'batch_shape': [1, 833], 'correct_preds': [[2387, 2626]]}\n",
      "{'batch_shape': [2, 420], 'correct_preds': [[1699, 1930]]}\n",
      "{'batch_shape': [3, 352], 'correct_preds': [[2529, 2775], [1690, 1919]]}\n",
      "{'batch_shape': [1, 987], 'correct_preds': []}\n",
      "{'batch_shape': [2, 537], 'correct_preds': [[1680, 1907]]}\n",
      "{'batch_shape': [5, 216], 'correct_preds': [[2035, 2264]]}\n",
      "{'batch_shape': [2, 438], 'correct_preds': [[1997, 2208], [2165, 2395]]}\n",
      "{'batch_shape': [2, 503], 'correct_preds': [[1928, 2156], [2105, 2338]]}\n",
      "{'batch_shape': [2, 451], 'correct_preds': [[1927, 2156]]}\n",
      "{'batch_shape': [1, 693], 'correct_preds': [[1840, 2080]]}\n",
      "{'batch_shape': [2, 516], 'correct_preds': [[2378, 2615]]}\n",
      "{'batch_shape': [4, 291], 'correct_preds': [[1674, 1893], [2144, 2373], [2027, 2247]]}\n",
      "{'batch_shape': [1, 630], 'correct_preds': []}\n",
      "{'batch_shape': [1, 697], 'correct_preds': []}\n",
      "{'batch_shape': [2, 492], 'correct_preds': []}\n",
      "{'batch_shape': [2, 614], 'correct_preds': [[2416, 2662]]}\n",
      "{'batch_shape': [2, 444], 'correct_preds': [[2684, 2945]]}\n",
      "{'batch_shape': [1, 775], 'correct_preds': []}\n",
      "{'batch_shape': [1, 668], 'correct_preds': []}\n",
      "{'batch_shape': [3, 327], 'correct_preds': []}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': []}\n",
      "{'batch_shape': [1, 869], 'correct_preds': []}\n",
      "{'batch_shape': [2, 470], 'correct_preds': [[1666, 1883], [1725, 1970]]}\n",
      "{'batch_shape': [4, 256], 'correct_preds': [[2410, 2648], [3038, 3312]]}\n",
      "{'batch_shape': [1, 682], 'correct_preds': [[2727, 2989]]}\n",
      "{'batch_shape': [3, 388], 'correct_preds': [[2604, 2865]]}\n",
      "{'batch_shape': [2, 585], 'correct_preds': [[1672, 1892]]}\n",
      "{'batch_shape': [1, 619], 'correct_preds': []}\n",
      "{'batch_shape': [2, 561], 'correct_preds': []}\n",
      "{'batch_shape': [1, 752], 'correct_preds': []}\n",
      "{'batch_shape': [3, 383], 'correct_preds': [[1601, 1812], [1996, 2208]]}\n",
      "{'batch_shape': [2, 513], 'correct_preds': []}\n",
      "{'batch_shape': [1, 628], 'correct_preds': [[1676, 1895]]}\n",
      "{'batch_shape': [1, 776], 'correct_preds': [[1711, 1954]]}\n",
      "{'batch_shape': [1, 971], 'correct_preds': []}\n",
      "{'batch_shape': [1, 644], 'correct_preds': []}\n",
      "{'batch_shape': [1, 941], 'correct_preds': [[1926, 2156]]}\n",
      "{'batch_shape': [2, 560], 'correct_preds': []}\n",
      "{'batch_shape': [1, 670], 'correct_preds': [[1588, 1800]]}\n",
      "{'batch_shape': [1, 977], 'correct_preds': []}\n",
      "{'batch_shape': [1, 803], 'correct_preds': [[2440, 2688]]}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': [[1715, 1956]]}\n",
      "{'batch_shape': [1, 630], 'correct_preds': [[2918, 3182]]}\n",
      "{'batch_shape': [1, 757], 'correct_preds': [[1966, 2185]]}\n",
      "{'batch_shape': [1, 896], 'correct_preds': [[1669, 1890]]}\n",
      "{'batch_shape': [3, 410], 'correct_preds': []}\n",
      "{'batch_shape': [1, 645], 'correct_preds': []}\n",
      "{'batch_shape': [1, 667], 'correct_preds': []}\n",
      "{'batch_shape': [1, 655], 'correct_preds': [[2348, 2582]]}\n",
      "{'batch_shape': [1, 642], 'correct_preds': []}\n",
      "{'batch_shape': [1, 637], 'correct_preds': []}\n",
      "{'batch_shape': [1, 650], 'correct_preds': []}\n",
      "{'batch_shape': [1, 991], 'correct_preds': []}\n",
      "{'batch_shape': [1, 942], 'correct_preds': []}\n",
      "{'batch_shape': [1, 636], 'correct_preds': []}\n",
      "{'batch_shape': [1, 698], 'correct_preds': []}\n",
      "{'batch_shape': [1, 706], 'correct_preds': []}\n",
      "{'batch_shape': [2, 527], 'correct_preds': [[2630, 2881]]}\n",
      "{'batch_shape': [1, 659], 'correct_preds': [[1679, 1904]]}\n",
      "{'batch_shape': [1, 665], 'correct_preds': [[1682, 1909]]}\n",
      "{'batch_shape': [1, 949], 'correct_preds': [[1673, 1893]]}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [1, 977], 'correct_preds': [[1686, 1916]]}\n",
      "Evaluation result: seqs: 288, tokens: 63,797, loss: 4.144, total_acc: [0.4861111], total_precision: [0.24151236], total_recall: [0.084333666], f1: [0.11370614], accs: 46.88%, distances: 16.465\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -e True -m finetune_transformer --log finetune_transformer/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'model': {'configuration': 'ggnn', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'model_2': {'configuration': 'transformer', 'base': {'hidden_dim': 256, 'dropout_rate': 0.1, 'num_edge_types': 24}, 'evaluation': {'top': 1, 'node_of_line': 7, 'window_size': 9}, 'ggnn': {'time_steps': [3, 1, 3, 1], 'residuals': {'1': [0], '3': [0, 1]}, 'add_type_bias': True}, 'transformer': {'ff_dim': 2048, 'num_layers': 6, 'attention_dim': 512, 'num_heads': 8}}, 'data': {'max_batch_size': 1250, 'max_buffer_size': 100, 'max_node_size': 1024, 'valid_interval': 2500, 'max_valid_samples': 25000, 'max_token_length': 10, 'w2v_dimension': 256}, 'training': {'max_steps': 50, 'print_freq': 500, 'learning_rate': 1e-05}}\n",
      "Restoring top model from step: 48\n",
      "Restoring top model from step: 40\n",
      "Testing pre-trained model on full eval data\n",
      "{'batch_shape': [1, 776], 'correct_preds': [[1711, 1954]]}\n",
      "{'batch_shape': [6, 194], 'correct_preds': [[1683, 1909], [1895, 2123], [2320, 2563]]}\n",
      "{'batch_shape': [3, 349], 'correct_preds': [[1960, 2179]]}\n",
      "{'batch_shape': [18, 61], 'correct_preds': [[1694, 1923], [1671, 1892], [1693, 1922], [1704, 1945], [1709, 1953], [1722, 1966], [1965, 2185], [1716, 1957], [1995, 2208]]}\n",
      "{'batch_shape': [4, 287], 'correct_preds': [[2027, 2247]]}\n",
      "{'batch_shape': [13, 89], 'correct_preds': [[2081, 2307], [2183, 2414], [2656, 2921], [1676, 1896], [2617, 2869]]}\n",
      "{'batch_shape': [1, 971], 'correct_preds': []}\n",
      "{'batch_shape': [5, 225], 'correct_preds': [[1708, 1953], [2140, 2370]]}\n",
      "{'batch_shape': [3, 352], 'correct_preds': []}\n",
      "{'batch_shape': [8, 144], 'correct_preds': [[2872, 3134], [2316, 2560], [2361, 2602], [2800, 3054]]}\n",
      "{'batch_shape': [2, 533], 'correct_preds': [[1684, 1911]]}\n",
      "{'batch_shape': [6, 190], 'correct_preds': [[2502, 2746], [2557, 2816], [2791, 3045], [2411, 2652]]}\n",
      "{'batch_shape': [10, 117], 'correct_preds': [[1649, 1865], [1655, 1871], [1724, 1967], [1667, 1884]]}\n",
      "{'batch_shape': [2, 422], 'correct_preds': [[2523, 2772]]}\n",
      "{'batch_shape': [4, 274], 'correct_preds': [[2181, 2414]]}\n",
      "{'batch_shape': [11, 107], 'correct_preds': [[2021, 2237]]}\n",
      "{'batch_shape': [9, 136], 'correct_preds': [[2593, 2855], [2446, 2691], [2800, 3056]]}\n",
      "{'batch_shape': [5, 238], 'correct_preds': [[2319, 2561], [2510, 2757], [3038, 3312]]}\n",
      "{'batch_shape': [2, 561], 'correct_preds': []}\n",
      "{'batch_shape': [5, 220], 'correct_preds': [[2844, 3114], [1664, 1883]]}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [4, 295], 'correct_preds': [[1674, 1893], [2144, 2373], [2243, 2475], [1560, 1771]]}\n",
      "{'batch_shape': [13, 93], 'correct_preds': [[2913, 3181], [2894, 3162], [2924, 3193], [2987, 3266], [2705, 2964], [2792, 3045], [2581, 2847], [2792, 3046], [2768, 3013], [1850, 2088]]}\n",
      "{'batch_shape': [2, 549], 'correct_preds': [[1717, 1960]]}\n",
      "{'batch_shape': [3, 363], 'correct_preds': [[2249, 2482]]}\n",
      "{'batch_shape': [2, 538], 'correct_preds': [[1680, 1907]]}\n",
      "{'batch_shape': [1, 668], 'correct_preds': []}\n",
      "{'batch_shape': [2, 619], 'correct_preds': [[2416, 2662]]}\n",
      "{'batch_shape': [3, 346], 'correct_preds': [[2529, 2775], [2664, 2929], [1701, 1939]]}\n",
      "{'batch_shape': [3, 386], 'correct_preds': [[2604, 2865]]}\n",
      "{'batch_shape': [4, 303], 'correct_preds': [[1665, 1883]]}\n",
      "{'batch_shape': [7, 168], 'correct_preds': [[2984, 3262], [2605, 2865], [2599, 2860], [2441, 2688]]}\n",
      "{'batch_shape': [5, 210], 'correct_preds': [[2035, 2264]]}\n",
      "{'batch_shape': [4, 252], 'correct_preds': [[1677, 1901], [2410, 2648]]}\n",
      "{'batch_shape': [3, 327], 'correct_preds': []}\n",
      "{'batch_shape': [3, 387], 'correct_preds': [[1601, 1812], [1996, 2208]]}\n",
      "{'batch_shape': [4, 268], 'correct_preds': [[1728, 1974], [2000, 2219]]}\n",
      "{'batch_shape': [6, 199], 'correct_preds': [[2632, 2884], [2883, 3144]]}\n",
      "{'batch_shape': [8, 96], 'correct_preds': [[2803, 3058], [2705, 2965], [2420, 2663], [2622, 2876]]}\n",
      "{'batch_shape': [2, 416], 'correct_preds': [[1699, 1930]]}\n",
      "{'batch_shape': [2, 447], 'correct_preds': [[2684, 2945]]}\n",
      "{'batch_shape': [4, 308], 'correct_preds': [[2580, 2844], [2223, 2450]]}\n",
      "{'batch_shape': [2, 585], 'correct_preds': [[1672, 1892]]}\n",
      "{'batch_shape': [2, 470], 'correct_preds': [[1725, 1970], [1666, 1883]]}\n",
      "{'batch_shape': [1, 693], 'correct_preds': [[1840, 2080]]}\n",
      "{'batch_shape': [1, 650], 'correct_preds': []}\n",
      "{'batch_shape': [1, 628], 'correct_preds': [[1676, 1895]]}\n",
      "{'batch_shape': [1, 987], 'correct_preds': []}\n",
      "{'batch_shape': [1, 894], 'correct_preds': [[2299, 2531]]}\n",
      "{'batch_shape': [1, 697], 'correct_preds': []}\n",
      "{'batch_shape': [1, 741], 'correct_preds': []}\n",
      "{'batch_shape': [2, 516], 'correct_preds': [[2378, 2615]]}\n",
      "{'batch_shape': [2, 548], 'correct_preds': [[1718, 1960]]}\n",
      "{'batch_shape': [2, 503], 'correct_preds': [[1928, 2156], [2105, 2338]]}\n",
      "{'batch_shape': [1, 752], 'correct_preds': []}\n",
      "{'batch_shape': [3, 315], 'correct_preds': [[1675, 1895], [2767, 3012]]}\n",
      "{'batch_shape': [3, 392], 'correct_preds': [[2102, 2330], [1668, 1885]]}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': []}\n",
      "{'batch_shape': [1, 833], 'correct_preds': [[2387, 2626]]}\n",
      "{'batch_shape': [1, 655], 'correct_preds': [[2348, 2582]]}\n",
      "{'batch_shape': [1, 1008], 'correct_preds': [[1715, 1956]]}\n",
      "{'batch_shape': [3, 322], 'correct_preds': [[2579, 2841]]}\n",
      "{'batch_shape': [2, 526], 'correct_preds': []}\n",
      "{'batch_shape': [1, 942], 'correct_preds': []}\n",
      "{'batch_shape': [1, 869], 'correct_preds': []}\n",
      "{'batch_shape': [2, 436], 'correct_preds': [[2165, 2395]]}\n",
      "{'batch_shape': [1, 636], 'correct_preds': []}\n",
      "{'batch_shape': [1, 605], 'correct_preds': []}\n",
      "{'batch_shape': [1, 645], 'correct_preds': []}\n",
      "{'batch_shape': [1, 855], 'correct_preds': [[2603, 2865]]}\n",
      "{'batch_shape': [3, 333], 'correct_preds': [[1690, 1919]]}\n",
      "{'batch_shape': [1, 918], 'correct_preds': []}\n",
      "{'batch_shape': [2, 516], 'correct_preds': []}\n",
      "{'batch_shape': [1, 684], 'correct_preds': [[1581, 1793]]}\n",
      "{'batch_shape': [1, 682], 'correct_preds': [[2727, 2989]]}\n",
      "{'batch_shape': [2, 535], 'correct_preds': []}\n",
      "{'batch_shape': [1, 644], 'correct_preds': []}\n",
      "{'batch_shape': [2, 507], 'correct_preds': [[2630, 2881]]}\n",
      "{'batch_shape': [2, 336], 'correct_preds': [[2419, 2663], [3027, 3303]]}\n",
      "{'batch_shape': [1, 665], 'correct_preds': [[1682, 1909]]}\n",
      "{'batch_shape': [1, 630], 'correct_preds': []}\n",
      "{'batch_shape': [1, 757], 'correct_preds': [[1966, 2185]]}\n",
      "{'batch_shape': [1, 778], 'correct_preds': [[1614, 1828]]}\n",
      "{'batch_shape': [1, 991], 'correct_preds': []}\n",
      "{'batch_shape': [1, 706], 'correct_preds': []}\n",
      "{'batch_shape': [2, 438], 'correct_preds': [[2930, 3198], [1997, 2208]]}\n",
      "{'batch_shape': [1, 977], 'correct_preds': []}\n",
      "{'batch_shape': [2, 479], 'correct_preds': [[1927, 2156]]}\n",
      "{'batch_shape': [1, 951], 'correct_preds': []}\n",
      "{'batch_shape': [1, 670], 'correct_preds': [[1588, 1800]]}\n",
      "{'batch_shape': [1, 667], 'correct_preds': []}\n",
      "{'batch_shape': [1, 630], 'correct_preds': [[2918, 3182]]}\n",
      "{'batch_shape': [1, 949], 'correct_preds': [[1673, 1893]]}\n",
      "{'batch_shape': [1, 698], 'correct_preds': []}\n",
      "{'batch_shape': [1, 775], 'correct_preds': []}\n",
      "{'batch_shape': [1, 803], 'correct_preds': [[2440, 2688]]}\n",
      "{'batch_shape': [1, 896], 'correct_preds': [[1669, 1890]]}\n",
      "{'batch_shape': [1, 941], 'correct_preds': [[1926, 2156]]}\n",
      "{'batch_shape': [1, 946], 'correct_preds': [[1826, 2067]]}\n",
      "{'batch_shape': [1, 641], 'correct_preds': [[2606, 2865]]}\n",
      "{'batch_shape': [1, 637], 'correct_preds': []}\n",
      "{'batch_shape': [1, 642], 'correct_preds': []}\n",
      "{'batch_shape': [1, 977], 'correct_preds': [[1686, 1916]]}\n",
      "{'batch_shape': [1, 659], 'correct_preds': [[1679, 1904]]}\n",
      "{'batch_shape': [1, 560], 'correct_preds': []}\n",
      "Evaluation result: seqs: 288, tokens: 63,797, loss: 3.984, total_acc: [0.4652778], total_precision: [0.1701389], total_recall: [0.05990961], f1: [0.08084491], accs: 45.83%, distances: 16.576\n"
     ]
    }
   ],
   "source": [
    "%run VELVET\\src\\run_model.py data\\dataset_d2a VELVET\\src\\config.yml -t True -x finetune_gnn -y finetune_transformer -p finetune_gnn/log.txt -q finetune_transformer/log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
